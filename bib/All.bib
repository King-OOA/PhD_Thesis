@Comment{jabref-meta: keypatterndefault:[auth][year];}

@Comment{jabref-meta: pdfDirectory:/home/pz/Documents/literatures/Dict
ionary_Matching;}


@InProceedings{Agarwal2013,
	Title = {A high-speed and large-scale dictionary matching engine for Information Extraction systems},
	Author = {Agarwal, K. and Polig, R.},
	Booktitle = {Application-Specific Systems, Architectures and Processors (ASAP), 2013 IEEE 24th International Conference on},
	Year = {2013},
	Month = {June},
	Pages = {59-66},
	Abstract = {Dictionary matching is a commonly used operation in Information Extraction (IE) systems. It involves matching a set of strings in a document against a dictionary of pre-defined patterns. In this paper, we describe a high performance and scalable hardware architecture to enable high throughput dictionary matching on very large dictionaries for text analytics applications. Our hardware accelerator employs a novel hashing based approach instead of commonly used deterministic finite automata (DFA) based algorithms. A limitation of the DFA based approaches is that they typically process one character every cycle, while the proposed hash based scheme can process a string token every cycle, thus achieving significantly higher processing throughput than the DFA based implementations. Our measurement results based on a prototype implementation on an Altera Stratix IV FPGA device indicate that our hardware dictionary matching engine can process typical document streams at a processing rate of ~1.5GB/s (~12 Gbps) while simultaneously allowing support for large dictionary sizes containing up to ~100K patterns, thus making it very useful for IE workload acceleration.},
	Doi = {10.1109/ASAP.2013.6567551},
	File = {Agarwal2013.pdf:Agarwal2013.pdf:PDF},
	Imestamp = {2016.02.24},
	ISSN = {2160-0511},
	Keywords = {dictionaries;field programmable gate arrays;file organisation;information retrieval systems;string matching;text analysis;Altera Stratix IV FPGA device;DFA based algorithms;IE systems;IE workload acceleration;deterministic finite automata based algorithms;hardware accelerator;hardware dictionary matching engine;hashing based approach;high throughput dictionary matching;high-speed dictionary matching engine;information extraction system;large-scale dictionary matching engine;scalable hardware architecture;string matching;string token;text analytics applications;Arrays;Dictionaries;Field programmable gate arrays;Hardware;Pattern matching;Random access memory;Throughput;FPGA;dictionary matching;hardware acceleration;hashing;information extraction;pattern matching;string matching;text analytics},
	Owner = {pz}
}

@Article{Aho1975,
	Title = {Efficient String Matching: An Aid to Bibliographic Search},
	Author = {Aho, Alfred V. and Corasick, Margaret J.},
	Journal = {Commun. ACM},
	Year = {1975},
	Month = jun,
	Note = {AC},
	Number = {6},
	Pages = {333--340},
	Volume = {18},
	Acmid = {360855},
	Address = {New York, NY, USA},
	Doi = {10.1145/360825.360855},
	File = {Aho1975.pdf:Aho1975.pdf:PDF},
	ISSN = {0001-0782},
	Issue_date = {June 1975},
	Keywords = {bibliographic search, computational complexity, finite state machines, information retrieval, keywords and phrases, string pattern matching, text-editing},
	Numpages = {8},
	Publisher = {ACM},
	Url = {http://doi.acm.org/10.1145/360825.360855}
}

@Article{Amir2015,
	Title = {Dictionary matching with a few gaps },
	Author = {Amihood Amir and Avivit Levy and Ely Porat and B. Riva Shalom},
	Journal = {Theoretical Computer Science },
	Year = {2015},
	Pages = {34 - 46},
	Volume = {589},
	Abstract = {Abstract The dictionary matching with gaps problem is to preprocess a dictionary D of total size | D | containing d gapped patterns P 1 , … , P d over an alphabet Σ, where each gapped pattern P i is a sequence of subpatterns separated by bounded sequences of don't cares. Then, given a query text T of length n over Σ, the goal is to output all locations in T in which a pattern P i ∈ D , 1 ≤ i ≤ d , ends. There is a renewed current interest in the gapped matching problem stemming from cyber security. In this paper we solve the problem where all patterns in the dictionary have one gap or a few gaps with at least α and at most β don't cares, where α and β are given parameters. Specifically, we show that the dictionary matching with a single gap problem can be solved in either O ( d log ⁡ d + | D | ) preprocessing time and O ( d log ε ⁡ d + | D | ) space, and query time O ( n ( β − α ) log ⁡ log ⁡ d log 2 ⁡ | D | + occ ) , where occ is the number of patterns found, or preprocessing time and space: O ( d 2 + | D | ) , and query time O ( n ( β − α ) + occ ) , where occ is the number of patterns found. We also show that the dictionary matching with k gaps problem, where k ≥ 1 , can be solved in preprocessing time: O ( | D | log ⁡ | D | ) , space: O ( | D | + d ( c 1 log ⁡ d ) k k ! ) , and query time: O ( ( β − α ) k ( n + ( c 2 log ⁡ d ) k k ! log ⁡ log ⁡ | D | ) + occ ) , where c 1 , c 2 &gt; 1 are constants and occ is the number of patterns found. As far as we know, these are the best solutions for this setting of the problem, where many overlaps may exist in the dictionary. },
	Doi = {http://dx.doi.org/10.1016/j.tcs.2015.04.011},
	File = {Amir2015.pdf:Amir2015.pdf:PDF},
	ISSN = {0304-3975},
	Keywords = {String matching},
	Owner = {pz},
	Timestamp = {2016.02.24},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304397515003187}
}

@article{Apostolico1992,
	timestamp = {四 4月 20 11:16:27 2017},
	title = "Fast linear-space computations of longest common subsequences ",
	journal = "Theoretical Computer Science ",
	volume = "92",
	number = "1",
	pages = "3 - 17",
	year = "1992",
	note = "",
	issn = "0304-3975",
	doi = "http://dx.doi.org/10.1016/0304-3975(92)90132-Y",
	url = "http://www.sciencedirect.com/science/article/pii/030439759290132Y",
	author = "A. Apostolico and S. Browne and C. Guerra",
	abstract = "Space saving techniques in computations of a longest common subsequence (LCS) of two strings are crucial in many applications, notably, in molecular sequence comparisons. For about ten years, however, the only linear-space \{LCS\} algorithm known required time quadratic in the length of the input, for all inputs. This paper reviews linear-space \{LCS\} computations in connection with two classical paradigms originally designed to take less than quadratic time in favorable circumstances. The objective is to achieve the space reduction without alteration of the asymptotic time complexity of the original algorithm. The first one of the resulting constructions takes time O(n(m−l)), and is thus suitable for cases where the \{LCS\} is expected to be close to the shortest input string. The second takes time O(ml log(min[s, m, 2nl])) and suits cases where one of the inputs is much shorter than the other. Here m and n (m⩽n) are the lengths of the two input strings, l is the length of the longest common subsequences and s is the size of the alphabet. Along the way, a very simple O(m(m−l)) time algorithm is also derived for the case of strings of equal length. "
}

@Article{Aravanis2017,
	doi = {10.1016/j.cell.2017.01.030},
	pages = {571-574},
	number = {4},
	volume = {168},
	year = {2017},
	journal = {Cell},
	title = {Next-Generation Sequencing of Circulating Tumor DNA for Early Cancer Detection},
	author = { Alexander M. Aravanis, Mark Lee, Richard, D. Klausner},
	timestamp = {二 6月 27 16:01:37 2017}
}

@article{Arroyuelo2014,
	timestamp = {三 8月 16 21:13:12 2017},
	title = {Distributed text search using suffix arrays},
	author = {Arroyuelo, Diego and Bonacic, Carolina and Gil-Costa, Veronica and Marin, Mauricio and Navarro, Gonzalo},
	journal = {Parallel Computing},
	volume = {40},
	number = {9},
	pages = {471-495},
	year = {2014}
}

@article{Bawono2017,
	timestamp = {三 8月 16 19:59:56 2017},
	title = {Multiple Sequence Alignment.},
	author = {Bawono, P and Dijkstra, M and Pirovano, W and Feenstra, A and Abeln, S and Heringa, J},
	journal = {Methods in Molecular Biology},
	volume = {1525},
	number = {2},
	pages = {167},
	year = {2017}
}

@article{Bentley1993,
	timestamp = {六 8月 12 17:53:46 2017},
	title = {Engineering a sort function},
	author = {Bentley, Jon L and McIlroy, M Douglas},
	journal = {Software: Practice and Experience},
	volume = {23},
	number = {11},
	pages = {1249--1265},
	year = {1993},
	publisher = {Wiley Online Library}
}

@article{Bing2007,
	timestamp = {三 8月 16 19:12:25 2017},
	title = {Network-based malcode detection technology},
	author = {Bing, W. U. and Yun, Xiao Chun and Qi, Gao},
	journal = {Journal on Communications},
	year = {2007}
}

@Article{Boyer1977,
	timestamp = {六 8月 12 20:28:08 2017},
	Title = {A Fast String Searching Algorithm},
	Author = {Boyer, Robert S. and Moore, J. Strother},
	Journal = {Commun. ACM},
	Year = {1977},
	Month = oct,
	Note = {BM},
	Number = {10},
	Pages = {762--772},
	Volume = {20},
	Acmid = {359859},
	Address = {New York, NY, USA},
	Doi = {10.1145/359842.359859},
	File = {Boyer1977.pdf:Boyer1977.pdf:PDF},
	ISSN = {0001-0782},
	Issue_date = {Oct. 1977},
	Keywords = {bibliographic search, computational complexity, information retrieval, linear time bound, pattern matching, text editing},
	Numpages = {11},
	Publisher = {ACM},
	Url = {http://doi.acm.org/10.1145/359842.359859}
}

@InProceedings{Bremler2011,
	timestamp = {六 8月 12 20:33:53 2017},
	Title = {Space-time tradeoffs in software-based deep Packet Inspection},
	Author = {A. Bremler-Barr and Y. Harchol and D. Hay},
	Booktitle = {High Performance Switching and Routing (HPSR), 2011 IEEE 12th International Conference on},
	Year = {2011},
	Month = {July},
	Pages = {1-8},
	Doi = {10.1109/HPSR.2011.5985996},
	File = {Bremler-Barr2011.pdf:Bremler-Barr2011.pdf:PDF},
	Keywords = {Internet;authorisation;computer networks;AC algorithm;Aho-Corasick automaton;DPI;NIDS systems;Web application firewalls;algorithmic complexity attacks;compression technique;deterministic finite automaton;network intrusion detection;packet inspection;packet processing;prevention systems;software-based deep;space-time tradeoffs;state transition;Automata;Doped fiber amplifiers;Encoding;Pattern matching;Software;Software algorithms;Throughput}
}

@inproceedings{Brisaboa2015,
	timestamp = {三 8月 16 21:32:58 2017},
	title = {A compact RDF store using suffix arrays},
	author = {Brisaboa, Nieves R and Cerdeira-Pena, Ana and Farina, Antonio and Navarro, Gonzalo},
	booktitle = {International Symposium on String Processing and Information Retrieval},
	pages = {103--115},
	year = {2015},
	organization = {Springer}
}

@inproceedings{Burkhardt2003,
	timestamp = {六 8月 12 17:54:56 2017},
	title = {Fast lightweight suffix array construction and checking},
	author = {Burkhardt, Stefan and K{\"a}rkk{\"a}inen, Juha},
	booktitle = {Annual Symposium on Combinatorial Pattern Matching},
	pages = {55--69},
	year = {2003},
	organization = {Springer}
}

@article{Chattopadhyay2016,
	timestamp = {三 8月 16 19:22:55 2017},
	title = {Genome-wide mitochondrial DNA sequence variations and lower expression of OXPHOS genes predict mitochondrial dysfunction in oral cancer tissue},
	author = {Chattopadhyay, Esita and Sarkar, Navonil De and Singh, Richa and Ray, Anindita and Roy, Roshni and Paul, Ranjan Rashmi and Pal, Mousumi and Ghose, Sandip and Ghosh, Subhrendu and Kabiraj, Debajyoti},
	journal = {Tumor Biology},
	volume = {37},
	number = {9},
	pages = {11861-11871},
	year = {2016}
}

@article{Chatzou2015,
	timestamp = {三 8月 16 20:01:03 2017},
	title = {Multiple sequence alignment modeling: methods and applications.},
	author = {Chatzou, M and Magis, C and Chang, J. M. and Kemena, C and Bussotti, G and Erb, I and Notredame, C},
	journal = {Briefings in Bioinformatics},
	volume = {17},
	number = {6},
	pages = {1009},
	year = {2015}
}

@article{Chen2006,
	timestamp = {四 4月 20 11:16:27 2017},
	Author = {Chen, Yixin and Wan, Andrew and Liu, Wei},
	Title = {{A fast parallel algorithm for finding the longest common sequence of
   multiple biosequences}},
	Journal = {{BMC BIOINFORMATICS}},
	Year = {2006},
	Volume = {{7}},
	Number = {{4}},
	Note = {{Symposium of Computations in Bioinformatics and Bioscience in
   Conjunction with the International Mult-Symposium on Computer and
   Computational Sciences, Hangzhou, PEOPLES R CHINA, JUN 20-24, 2006}},
	Abstract = {{Background: Searching for the longest common sequence (LCS) of multiple
   biosequences is one of the most fundamental tasks in bioinformatics. In
   this paper, we present a parallel algorithm named FAST\_LCS to speedup
   the computation for finding LCS.
   Results: A fast parallel algorithm for LCS is presented. The algorithm
   first constructs a novel successor table to obtain all the identical
   pairs and their levels. It then obtains the LCS by tracing back from the
   identical character pairs at the last level. Effective pruning
   techniques are developed to significantly reduce the computational
   complexity. Experimental results on gene sequences in the tigr database
   show that our algorithm is optimal and much more efficient than other
   leading LCS algorithms.
   Conclusion: We have developed one of the fastest parallel LCS algorithms
   on an MPP parallel computing model. For two sequences X and Y with
   lengths n and m, respectively, the memory required is max\{4{*}(n+ 1)+
   4{*}(m+ 1), L\}, where L is the number of identical character pairs. The
   time complexity is O(L) for sequential execution, and O(vertical bar
   LCS(X, Y)vertical bar) for parallel execution, where vertical bar LCS(X,
   Y)vertical bar is the length of the LCS of X and Y. For n sequences X-1,
   X-2, ..., X-n, the time complexity is O(L) for sequential execution, and
   O(vertical bar LCS(X-1, X-2,..., X-n)vertical bar) for parallel
   execution. Experimental results support our analysis by showing
   significant improvement of the proposed method over other leading LCS
   algorithms.}},
	Publisher = {{BIOMED CENTRAL LTD}},
	Address = {{MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND}},
	Type = {{Article; Proceedings Paper}},
	Language = {{English}},
	Affiliation = {{Chen, YX (Reprint Author), Washington Univ, Dept Comp Sci \& Engn, St Louis, MO 63130 USA.
   Washington Univ, Dept Comp Sci \& Engn, St Louis, MO 63130 USA.
   Yangzhou Univ, Dept Comp Sci, Yangzhou 225009, Peoples R China.}},
	DOI = {{10.1186/1471-2105-7-S4-S4}},
	Article-Number = {{S4}},
	ISSN = {{1471-2105}},
	Keywords-Plus = {{SUBSEQUENCE PROBLEM; ALIGNMENT; ARRAY; SEARCH; TOOL}},
	Research-Areas = {{Biochemistry \& Molecular Biology; Biotechnology \& Applied
   Microbiology; Mathematical \& Computational Biology}},
	Web-of-Science-Categories = {{Biochemical Research Methods; Biotechnology \& Applied Microbiology;
   Mathematical \& Computational Biology}},
	Author-Email = {{chen@cse.wustl.edu
   awan@wustl.edu
   yzliuwei@126.com}},
	Number-of-Cited-References = {{29}},
	Times-Cited = {{8}}
}

@article{Chien2015,
	timestamp = {三 8月 16 21:22:57 2017},
	title = {Geometric BWT: Compressed Text Indexing via Sparse Suffixes and Range Searching},
	author = {Chien, Yu Feng and Hon, Wing Kai and Shah, Rahul and Thankachan, Sharma V. and Vitter, Jeffrey Scott},
	journal = {Algorithmica},
	volume = {71},
	number = {2},
	pages = {258-278},
	year = {2015}
}

@Article{Choi2011,
	Title = {A fast pattern matching algorithm with multi-byte search unit for high-speed network security },
	Author = {Yoon-Ho Choi and Moon-Young Jung and Seung-Woo Seo},
	Journal = {Computer Communications },
	Year = {2011},
	Note = {L+1-MWM},
	Number = {14},
	Pages = {1750 - 1763},
	Volume = {34},
	Abstract = {A signature-based intrusion detection system identifies intrusions by comparing the data traffic with known signature patterns. In this process, matching of packet strings against signature patterns is the most time-consuming step and dominates the overall system performance. Many signature-based network intrusion detection systems (NIDS), e.g., the Snort, employ one or multiple pattern matching algorithms to detect multiple attack types. So far, many pattern matching algorithms have been proposed. Most of them use single-byte standard unit for search, while a few algorithms such as the Modified Wu–Manber (MWM) algorithm use typically two-byte unit, which guarantees better performance than others even as the number of different signatures increases. Among those algorithms, the \{MWM\} algorithm has been known as the fastest pattern matching algorithm when the patterns in a rule set rarely appear in packets. However, the matching time of the \{MWM\} algorithm increases as the length of the shortest pattern in a signature group decreases. In this paper, by extending the length of the shortest pattern, we minimize the pattern matching time of the algorithm which uses multi-byte unit. We propose a new pattern matching algorithm called the L+1-MWM algorithm for multi-pattern matching. The proposed algorithm minimizes the performance degradation that is originated from the dependency on the length of the shortest pattern. We show that the L+1-MWM algorithm improves the performance of the \{MWM\} algorithm by as much as 20% in average under various lengths of shortest patterns and normal traffic conditions. Moreover, when the length of the shortest pattern in a rule set is less than 5, the L+1-MWM algorithm shows 38.87% enhancement in average. We also conduct experiments on a real campus network and show that 12.48% enhancement is obtained in average. In addition, it is shown that the L+1-MWM algorithm provides a better performance than the \{MWM\} algorithm by as much as 25% in average under various numbers of signatures and normal traffic conditions, and 20.12% enhancement in average with real on-line traffic. },
	Doi = {http://dx.doi.org/10.1016/j.comcom.2011.03.014},
	File = {Choi2011.pdf:Choi2011.pdf:PDF},
	ISSN = {0140-3664},
	Keywords = {Network intrusion detection system},
	Owner = {pz},
	Timestamp = {六 8月 12 20:40:15 2017},
	Url = {http://www.sciencedirect.com/science/article/pii/S0140366411001216}
}

@article{Dai2009,
	timestamp = {三 8月 16 19:05:54 2017},
	title = {An aggressive algorithm for multiple string matching},
	author = {Dai, Liuling},
	journal = {Information Processing Letters},
	volume = {109},
	number = {11},
	pages = {553-559},
	year = {2009}
}

@article{Deo2013,
	timestamp = {三 8月 16 21:48:52 2017},
	author = {Deo, Mrinal and Keely, Sean},
	title = {Parallel Suffix Array and Least Common Prefix for the GPU},
	journal = {SIGPLAN Not.},
	issue_date = {August 2013},
	volume = {48},
	number = {8},
	month = feb,
	year = {2013},
	issn = {0362-1340},
	pages = {197--206},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/2517327.2442536},
	doi = {10.1145/2517327.2442536},
	acmid = {2442536},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {accelerated processing unit (apu), bwt, gpu, longest common prefix, opencl, prefix sum, suffix array, suffix tree}
}

@inproceedings{Dhaliwal2012,
	timestamp = {六 8月 12 17:36:56 2017},
	title = {Trends in suffix sorting: A survey of low memory algorithms},
	author = {Dhaliwal, Jasbir and Puglisi, Simon J and Turpin, Andrew},
	booktitle = {Proceedings of the Thirty-fifth Australasian Computer Science Conference-Volume 122},
	pages = {91--98},
	year = {2012},
	organization = {Australian Computer Society, Inc.}
}

@article{Dong2011,
	timestamp = {三 8月 16 19:10:24 2017},
	title = {Improved Multiple Patterns Matching Algorithm Based on WM Algorithm},
	author = {Dong, Ying Lianga and Xuan, Xue Huaa and Wang, De Minb},
	journal = {Journal of Jilin University},
	volume = {29},
	number = {4},
	pages = {382-386},
	year = {2011}
}

@article{Donnell2015,
	timestamp = {三 8月 16 19:28:50 2017},
	title = {DNA sequence-based identification of Fusarium : Current status and future directions},
	author = {O’Donnell, Kerry and Ward, Todd J. and Robert, Vincent A. R. G. and Crous, Pedro W. and Geiser, David M. and Kang, Seogchan},
	journal = {Phytoparasitica},
	volume = {43},
	number = {5},
	pages = {583-595},
	year = {2015}
}

@inproceedings{Farach1997,
	timestamp = {六 8月 12 17:48:06 2017},
	title = {Optimal suffix tree construction with large alphabets},
	author = {Farach, Martin},
	booktitle = {Foundations of Computer Science, 1997. Proceedings., 38th Annual Symposium on},
	pages = {137--143},
	year = {1997},
	organization = {IEEE}
}

@inproceedings{Fischer2017,
	timestamp = {三 8月 16 21:04:42 2017},
	title = {Engineering a Distributed Full-Text Index},
	author = {Fischer, Johannes and Kurpicz, Florian and Sanders, Peter},
	booktitle = {2017 Proceedings of the Ninteenth Workshop on Algorithm Engineering and Experiments (ALENEX)},
	pages = {120--134},
	year = {2017},
	organization = {SIAM}
}

@inproceedings{Flick2015,
	timestamp = {三 8月 16 21:47:33 2017},
	author = {Flick, Patrick and Aluru, Srinivas},
	title = {Parallel Distributed Memory Construction of Suffix and Longest Common Prefix Arrays},
	booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
	series = {SC '15},
	year = {2015},
	isbn = {978-1-4503-3723-6},
	location = {Austin, Texas},
	pages = {16:1--16:10},
	articleno = {16},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/2807591.2807609},
	doi = {10.1145/2807591.2807609},
	acmid = {2807609},
	publisher = {ACM},
	address = {New York, NY, USA}
}

@article{Hirschberg1977,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Hirschberg, Daniel S.},
	title = {Algorithms for the Longest Common Subsequence Problem},
	journal = {J. ACM},
	issue_date = {Oct. 1977},
	volume = {24},
	number = {4},
	month = oct,
	year = {1977},
	issn = {0004-5411},
	pages = {664--675},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/322033.322044},
	doi = {10.1145/322033.322044},
	acmid = {322044},
	publisher = {ACM},
	address = {New York, NY, USA}
}

@article{Hoare1962,
	timestamp = {六 8月 12 17:54:24 2017},
	title = {Quicksort},
	author = {Hoare, Charles AR},
	journal = {The Computer Journal},
	volume = {5},
	number = {1},
	pages = {10--16},
	year = {1962},
	publisher = {Oxford University Press}
}

@Article{Hon2013,
	Title = {Faster compressed dictionary matching },
	Author = {Wing-Kai Hon and Tsung-Han Ku and Rahul Shah and Sharma V. Thankachan and Jeffrey Scott Vitter},
	Journal = {Theoretical Computer Science },
	Year = {2013},
	Pages = {113 - 119},
	Volume = {475},
	Abstract = {Given a set D of d patterns, the dictionary matching problem is to index D such that for any query text T , we can locate the occurrences of any pattern within T efficiently. When D contains a total of n characters drawn from an alphabet of size σ , Hon et al. (2008) [12] gave an n H k ( D ) + o ( n log σ ) -bit index which supports a query in O ( | T | ( log ϵ n + log d ) + o c c ) time, where ϵ &gt; 0 and H k ( D ) denotes the k th-order entropy of D . Very recently, Belazzougui (2010) [3] has proposed an elegant scheme, which takes n log σ + O ( n ) bits of index space and supports a query in optimal O ( | T | + o c c ) time. In this paper, we provide connections between Belazzougui’s index and the \{XBW\} compression of Ferragina and Manzini (2005) [8], and show that Belazzougui’s index can be slightly modified to be stored in n H k ( D ) + O ( n ) bits, while query time remains optimal; this improves the compressed index by Hon et al. (2008) [12] in both space and time. },
	Doi = {http://dx.doi.org/10.1016/j.tcs.2012.10.050},
	File = {Hon2013.pdf:Hon2013.pdf:PDF},
	ISSN = {0304-3975},
	Owner = {pz},
	Timestamp = {2016.02.24},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304397512009826}
}

@Article{Hsu1984,
	timestamp = {四 4月 20 11:16:27 2017},
	author = "Hsu, W. J.
and Du, M. W.",
	title = "Computing a longest common subsequence for a set of strings",
	journal = "BIT Numerical Mathematics",
	year = "1984",
	volume = "24",
	number = "1",
	pages = "45--59",
	abstract = "The known 2-string LCS problem is generalized to finding a Longest Common Subsequence (LCS) for a set of strings. A new, general approach that systematically enumerates common subsequences is proposed for the solution. Assuming a finite symbol set, it is shown that the presented scheme requires a preprocessing time that grows linearly with the total length of the input strings and a processing time that grows linearly with (K), the number of strings, and (∥ℙ∥) the number of matches among them. The only previous algorithm for the generalized LCS problem takesO(K{\textperiodcentered}|S1|{\textperiodcentered}|S2|{\textperiodcentered}...|S                  k                |) execution time, where |S                  i                | denotes the length of the stringS                  i                . Since typically ∥ℙ∥ is a very small percentage of |S1|{\textperiodcentered}|S2|{\textperiodcentered}...{\textperiodcentered}|S                  k                |, the proposed method may be considered to be much more efficient than the straightforward dynamic programming approach.",
	issn = "1572-9125",
	doi = "10.1007/BF01934514",
	url = "http://dx.doi.org/10.1007/BF01934514"
}

@InProceedings{Huang2008,
	Title = {A GPU-Based Multiple-Pattern Matching Algorithm for Network Intrusion Detection Systems},
	Author = {Nen-Fu Huang and Hsien-Wei Hung and Sheng-Hung Lai and Yen-Ming Chu and Wen-Yen Tsai},
	Booktitle = {Advanced Information Networking and Applications - Workshops, 2008. AINAW 2008. 22nd International Conference on},
	Year = {2008},
	Month = {March},
	Pages = {62-67},
	Abstract = {By the development of network applications, network security issues are getting more and more important. This paper proposes a multiple-pattern matching algorithm for the network intrusion detection systems based on the GPU (Graphics Processing Units). The highly parallelism of the GPU computation power is used to inspect the packet content in parallel. The performance of the proposed approach is analyzed through evaluations such as using various texture formats and different implementations. Experimental results indicate that the performance of the proposed approach is twice of that of the modified Wu-Manber algorithm used in Snort. The proposed approach makes a commodity and cheap GPU card as a high performance pattern matching co-processor.},
	Doi = {10.1109/WAINA.2008.145},
	File = {Huang2008.pdf:Huang2008.pdf:PDF},
	Keywords = {pattern matching;security of data;GPU computation power;graphics processing unit;multiple pattern matching algorithm;network application;network intrusion detection system;network security;packet content;pattern matching coprocessor;texture format;Application software;Communication system security;Computer graphics;Computer science;Concurrent computing;Coprocessors;Intrusion detection;Parallel processing;Pattern matching;Power engineering and energy;GPU;IDS;network security;pattern match},
	Owner = {pz},
	Timestamp = {2016.02.24}
}

@article{Hunt1977,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Hunt, James W. and Szymanski, Thomas G.},
	title = {A Fast Algorithm for Computing Longest Common Subsequences},
	journal = {Commun. ACM},
	issue_date = {May 1977},
	volume = {20},
	number = {5},
	month = may,
	year = {1977},
	issn = {0001-0782},
	pages = {350--353},
	numpages = {4},
	url = {http://doi.acm.org/10.1145/359581.359603},
	doi = {10.1145/359581.359603},
	acmid = {359603},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {efficient algorithms, longest common subsequence}
}

@Article{I2015,
	Title = {Compressed automata for dictionary matching },
	Author = {Tomohiro I and Takaaki Nishimoto and Shunsuke Inenaga and Hideo Bannai and Masayuki Takeda},
	Journal = {Theoretical Computer Science },
	Year = {2015},
	Note = {Implementation and Application of Automata },
	Pages = {30 - 41},
	Volume = {578},
	Abstract = {Abstract We address a variant of the dictionary matching problem where the dictionary is represented by a straight line program (SLP). For a given SLP-compressed dictionary D of size n and height h representing m patterns of total length N, we present an O ( n 2 log ⁡ N ) -size representation of Aho–Corasick automaton which recognizes all occurrences of the patterns in D in amortized O ( h + m ) running time per character. We also propose an algorithm to construct this compressed Aho–Corasick automaton in O ( n 3 log ⁡ n log ⁡ N ) time and O ( n 2 log ⁡ N ) space. In a spacial case where D represents only a single pattern, we present an O ( n log ⁡ N ) -size representation of the Morris–Pratt automaton which permits us to find all occurrences of the pattern in amortized O ( h ) running time per character, and we show how to construct this representation in O ( n 3 log ⁡ n log ⁡ N ) time with O ( n 2 log ⁡ N ) working space. },
	Doi = {http://dx.doi.org/10.1016/j.tcs.2015.01.019},
	File = {I2015.pdf:I2015.pdf:PDF},
	ISSN = {0304-3975},
	Keywords = {Straight line program},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304397515000468}
}

@inproceedings{Itoh1999,
	timestamp = {六 8月 12 17:49:03 2017},
	title = {An efficient method for in memory construction of suffix arrays},
	author = {Itoh, Hideo and Tanaka, Hozumi},
	booktitle = {String Processing and Information Retrieval Symposium, 1999 and International Workshop on Groupware},
	pages = {81--88},
	year = {1999},
	organization = {IEEE}
}

@article{Kandhan2010,
	timestamp = {六 8月 12 20:35:12 2017},
	title = {SigMatch: fast and scalable multi-pattern matching},
	author = {Kandhan, Ramakrishnan and Teletia, Nikhil and Patel, Jignesh M},
	journal = {Proceedings of the VLDB Endowment},
	volume = {3},
	number = {1-2},
	pages = {1173--1184},
	year = {2010},
	publisher = {VLDB Endowment}
}

@article{Karkkainen2006,
	timestamp = {六 8月 12 17:46:18 2017},
	title = {Linear work suffix array construction},
	author = {K{\"a}rkk{\"a}inen, Juha and Sanders, Peter and Burkhardt, Stefan},
	journal = {Journal of the ACM (JACM)},
	volume = {53},
	number = {6},
	pages = {918--936},
	year = {2006},
	publisher = {ACM}
}

@article{Karkkainen2014,
	timestamp = {六 8月 12 17:51:42 2017},
	title = {Engineering a lightweight external memory suffix array construction algorithm},
	author = {K{\"a}rkk{\"a}inen, Juha and Kempa, Dominik},
	journal = {Mathematics in Computer Science},
	pages = {1--13},
	year = {2014},
	publisher = {Springer}
}

@inproceedings{Karp1972,
	timestamp = {六 8月 12 17:35:15 2017},
	title = {Rapid identification of repeated patterns in strings, trees and arrays},
	author = {Karp, Richard M and Miller, Raymond E and Rosenberg, Arnold L},
	booktitle = {Proceedings of the fourth annual ACM symposium on Theory of computing},
	pages = {125--136},
	year = {1972},
	organization = {ACM}
}

@Article{Karp1987,
	timestamp = {六 8月 12 20:41:50 2017},
	Title = {Efficient randomized pattern-matching algorithms},
	Author = {R. M. Karp and M. O. Rabin},
	Journal = {IBM Journal of Research and Development},
	Year = {1987},
	Month = {March},
	Note = {Rabin-Karp},
	Number = {2},
	Pages = {249-260},
	Volume = {31},
	Doi = {10.1147/rd.312.0249},
	File = {Karp1987.pdf:Karp1987.pdf:PDF},
	ISSN = {0018-8646}
}

@article{Katoh2016,
	timestamp = {三 8月 16 19:56:54 2017},
	title = {A simple method to control over-alignment in the MAFFT multiple sequence alignment program},
	author = {Katoh, Kazutaka and Standley, Daron M.},
	journal = {Bioinformatics},
	volume = {32},
	number = {13},
	pages = {1933},
	year = {2016}
}

@Article{Khancome2013,
	Title = {A NEW LINEAR-TIME DYNAMIC DICTIONARY MATCHING ALGORITHM},
	Author = {Khancome, Chouvalit and Boonjing, Veera},
	Journal = {COMPUTING AND INFORMATICS},
	Year = {2013},
	Number = {5},
	Pages = {897-923},
	Volume = {32},
	Abstract = {This research presents inverted lists as a new data structure for the dynamic dictionary matching algorithm. The inverted lists structure, which derives from the inverted index, is implemented by the perfect hashing table. The dictionary is constructed in optimal time and the individual patterns can be updated in minimal time. The searching phase scans the given text in a single pass, even in a worst case scenario. In experimental results, the inverted lists used less time and space than the traditional structures; the searches were processed and showed an efficient linear time.},
	Address = {DUBRAVSKA CESTA 9, 84237 BRATISLAVA, SLOVAKIA},
	Affiliation = {Khancome, C (Reprint Author), KMITL, Fac Sci, Dept Math \& Comp Sci, Software Syst Engn Lab, Bangkok 10520, Thailand. Khancome, Chouvalit; Boonjing, Veera, KMITL, Fac Sci, Dept Math \& Comp Sci, Software Syst Engn Lab, Bangkok 10520, Thailand. Boonjing, Veera, PERDO, Natl Ctr Excellence Math, Bangkok 10400, Thailand.},
	Author-email = {Chouvalit@hotmail.com kbveera@kmitl.ac.th},
	Doc-delivery-number = {257TU},
	File = {Khancome2013.pdf:Khancome2013.pdf:PDF},
	ISSN = {1335-9150},
	Journal-iso = {Comput. Inform.},
	Keywords = {Dynamic dictionary matching; static dictionary matching; multiple pattern string matching; inverted index; inverted lists; trie; bit-parallel; hashing table},
	Keywords-plus = {INVERTED FILES; CONSTRUCTION; SEARCH; DNA},
	Language = {English},
	Number-of-cited-references = {41},
	Publisher = {SLOVAK ACAD SCIENCES INST INFORMATICS},
	Research-areas = {Computer Science},
	Times-cited = {0},
	Type = {Article},
	Unique-id = {ISI:000327410900001},
	Usage-count-since-2013 = {3},
	Web-of-science-categories = {Computer Science, Artificial Intelligence}
}

@article{Kim2005,
	timestamp = {六 8月 12 17:47:33 2017},
	title = {Constructing suffix arrays in linear time},
	author = {Kim, Dong Kyue and Sim, Jeong Seop and Park, Heejin and Park, Kunsoo},
	journal = {Journal of Discrete Algorithms},
	volume = {3},
	number = {2},
	pages = {126--142},
	year = {2005},
	publisher = {Elsevier}
}

@article{Kim2015,
	timestamp = {日 10月 30 13:08:16 2016},
	Author = {Kim, HyunJin and Choi, Kang-Il and Choi, Sang-Il},
	Title = {{A Memory-Efficient Deterministic Finite Automaton-Based Bit-Split String
   Matching Scheme Using Pattern Uniqueness in Deep Packet Inspection}},
	Journal = {{PLOS ONE}},
	Year = {2015},
	Volume = {{10}},
	Number = {{5}},
	Month = {{MAY 4}},
	Abstract = {{This paper proposes a memory-efficient bit-split string matching scheme
   for deep packet inspection (DPI). When the number of target patterns
   becomes large, the memory requirements of the string matching engine
   become a critical issue. The proposed string matching scheme reduces the
   memory requirements using the uniqueness of the target patterns in the
   deterministic finite automaton (DFA)-based bit-split string matching.
   The pattern grouping extracts a set of unique patterns from the target
   patterns. In the set of unique patterns, a pattern is not the suffix of
   any other patterns. Therefore, in the DFA constructed with the set of
   unique patterns, when only one pattern can be matched in an output
   state. In the bit-split string matching, multiple finite-state machine
   (FSM) tiles with several input bit groups are adopted in order to reduce
   the number of stored state transitions. However, the memory requirements
   for storing the matching vectors can be large because each bit in the
   matching vector is used to identify whether its own pattern is matched
   or not. In our research, the proposed pattern grouping is applied to the
   multiple FSM tiles in the bit-split string matching. For the set of
   unique patterns, the memory-based bit-split string matching engine
   stores only the pattern match index for each state to indicate the match
   with its own unique pattern. Therefore, the memory requirements are
   significantly decreased by not storing the matching vectors in the
   string matchers for the set of unique patterns. The experimental results
   show that the proposed string matching scheme can reduce the storage
   cost significantly compared to the previous bit-split string matching
   methods.}},
	Publisher = {{PUBLIC LIBRARY SCIENCE}},
	Address = {{1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA}},
	Type = {{Article}},
	Language = {{English}},
	Affiliation = {{Choi, SI (Reprint Author), Dankook Univ, Dept Appl Comp Engn, Yongin, South Korea.
   Kim, HyunJin, Dankook Univ, Sch Elect \& Elect Engn, Yongin, South Korea.
   Choi, Kang-Il, Elect \& Telecommun Res Inst, Adv Commun Res Lab, Taejon 305606, South Korea.
   Choi, Sang-Il, Dankook Univ, Dept Appl Comp Engn, Yongin, South Korea.}},
	DOI = {{10.1371/journal.pone.0126517}},
	Article-Number = {{e0126517}},
	ISSN = {{1932-6203}},
	Keywords-Plus = {{ARCHITECTURE; ALGORITHM}},
	Research-Areas = {{Science \& Technology - Other Topics}},
	Web-of-Science-Categories = {{Multidisciplinary Sciences}},
	Author-Email = {{choisi@dankook.ac.kr}},
	Funding-Acknowledgement = {{ICT R\&D program of the Ministry of Science, ICT \& Future
   Planning/Institute for Information \& communications Technology
   Promotion, Republic of Korea (Smart Networking Core Technology
   Development) {[}14-000-05-001]; Basic Science Research Program through
   the National Research Foundation of Korea (NRF) - Ministry of Science,
   ICT \& Future Planning {[}NRF-2012R1A1A1002993]}},
	Funding-Text = {{This work was partly supported by ICT R\&D program of the Ministry of
   Science, ICT \& Future Planning/Institute for Information \&
   communications Technology Promotion, Republic of Korea (14-000-05-001,
   Smart Networking Core Technology Development), and Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Science, ICT \& Future Planning
   (NRF-2012R1A1A1002993). The funders had no role in study design, data
   collection and analysis, decision to publish, or preparation of the
   manuscript.}},
	Number-of-Cited-References = {{27}},
	Times-Cited = {{2}}
}

@Article{Knuth1977,
	timestamp = {六 8月 12 20:26:21 2017},
	Title = {Fast Pattern Matching in Strings},
	Author = {Donald E. Knuth and James H. Morris, Jr. and Vaughan R. Pratt},
	Journal = {SIAM Journal on Computing},
	Year = {1977},
	Note = {KMP},
	Number = {2},
	Pages = {323-350},
	Volume = {6},
	Doi = {10.1137/0206024},
	Eprint = { http://dx.doi.org/10.1137/0206024 
},
	File = {Knuth1977.pdf:Knuth1977.pdf:PDF},
	Url = { http://dx.doi.org/10.1137/0206024 
}
}

@article{Ko2005,
	timestamp = {六 8月 12 17:45:45 2017},
	title = {Space efficient linear time construction of suffix arrays},
	author = {Ko, Pang and Aluru, Srinivas},
	journal = {Journal of Discrete Algorithms},
	volume = {3},
	number = {2},
	pages = {143--156},
	year = {2005},
	publisher = {Elsevier}
}

@article{Larsson2007,
	timestamp = {六 8月 12 17:43:40 2017},
	title = {Faster suffix sorting},
	author = {Larsson, N Jesper and Sadakane, Kunihiko},
	journal = {Theoretical Computer Science},
	volume = {387},
	number = {3},
	pages = {258--272},
	year = {2007},
	publisher = {Elsevier}
}

@Article{Le2013,
	Title = {A Memory-Efficient and Modular Approach for Large-Scale String Pattern Matching},
	Author = {Hoang Le and Prasanna, V.K.},
	Journal = {Computers, IEEE Transactions on},
	Year = {2013},
	Month = {May},
	Note = {MASM},
	Number = {5},
	Pages = {844-857},
	Volume = {62},
	Abstract = {In Network Intrusion Detection Systems (NIDSs), string pattern matching demands exceptionally high performance to match the content of network traffic against a predefined database (or dictionary) of malicious patterns. Much work has been done in this field; however, most of the prior work results in low memory efficiency (defined as the ratio of the amount of the required storage in bytes and the size of the dictionary in number of characters). Due to such inefficiency, state-of-the-art designs cannot support large dictionaries without using high-latency external DRAM. We propose an algorithm called "leaf-attaching" to preprocess a given dictionary without increasing the number of patterns. The resulting set of postprocessed patterns can be searched using any tree-search data structure. We also present a scalable, high-throughput, Memory-efficient Architecture for large-scale String Matching (MASM) based on a pipelined binary search tree. The proposed algorithm and architecture achieve a memory efficiency of 0.56 (for the Rogets dictionary) and 1.32 (for the Snort dictionary). As a result, our design scales well to support larger dictionaries. Implementations on 45 nm ASIC and a state-of-the-art FPGA device (for latest Rogets and Snort dictionaries) show that our architecture achieves 24 and 3.2 Gbps, respectively. The MASM module can simply be duplicated to accept multiple characters per cycle, leading to scalable throughput with respect to the number of characters processed in each cycle. Dictionary update involves simply rewriting the content of the memory, which can be done quickly without reconfiguring the chip.},
	Doi = {10.1109/TC.2012.38},
	File = {Le2013.pdf:Le2013.pdf:PDF;Le2013.pdf:Le2013.pdf:PDF},
	ISSN = {0018-9340},
	Keywords = {Internet;application specific integrated circuits;computer network security;field programmable gate arrays;storage management;string matching;tree searching;ASIC;FPGA device;MASM module;NIDS;Rogets dictionary;Snort dictionary;characters per cycle;content matching;dictionary dictionary;dictionary preprocessing;dictionary update;high-latency external DRAM;large-scale string pattern matching;leaf-attaching;malicious pattern dictionary;memory content rewriting;modular approach;network intrusion detection systems;network traffic;pipelined binary search tree;predefined database;scalable high-throughput memory-efficient architecture;tree-search data structure;Databases;Dictionaries;Memory management;Pattern matching;Throughput;Vectors;ASIC;Aho-Corasick;DFA;Databases;Dictionaries;Memory management;Pattern matching;Rogets;Snort;String matching;Throughput;Vectors;field-programmable gate array (FPGA);leaf attaching;pipeline;reconfigurable},
	Owner = {pz},
	Timestamp = {2016.02.24}
}

@Article{Lee2013,
	Title = {A Pattern-Matching Scheme With High Throughput Performance and Low Memory Requirement},
	Author = {Tsern-Huei Lee and Nai-Lun Huang},
	Journal = {Networking, IEEE/ACM Transactions on},
	Year = {2013},
	Month = {Aug},
	Note = {Pre-filter+AC},
	Number = {4},
	Pages = {1104-1116},
	Volume = {21},
	Abstract = {Pattern-matching techniques have recently been applied to network security applications such as intrusion detection, virus protection, and spam filters. The widely used Aho-Corasick (AC) algorithm can simultaneously match multiple patterns while providing a worst-case performance guarantee. However, as transmission technologies improve, the AC algorithm cannot keep up with transmission speeds in high-speed networks. Moreover, it may require a huge amount of space to store a two-dimensional state transition table when the total length of patterns is large. In this paper, we present a pattern-matching architecture consisting of a stateful pre-filter and an AC-based verification engine. The stateful pre-filter is optimal in the sense that it is equivalent to utilizing all previous query results. In addition, the filter can be easily realized with bitmaps and simple bitwise-AND and shift operations. The size of the two-dimensional state transition table in our proposed architecture is proportional to the number of patterns, as opposed to the total length of patterns in previous designs. Our proposed architecture achieves a significant improvement in both throughput performance and memory usage.},
	Doi = {10.1109/TNET.2012.2224881},
	File = {Lee2013.pdf:Lee2013.pdf:PDF},
	ISSN = {1063-6692},
	Keywords = {pattern matching;query processing;security of data;storage management;AC-based verification engine;Aho-Corasick algorithm;high throughput performance;information retrieval;intrusion detection;low memory requirement;network security applications;pattern-matching scheme;shift operations;spam filters;stateful pre-filter;text editing;two-dimensional state transition table;virus protection;Algorithm design and analysis;Data structures;Engines;IEEE transactions;Memory management;Pattern matching;Throughput;Aho–Corasick (AC) algorithm;Bloom filter;deep packet inspection;pattern matching},
	Owner = {pz},
	Timestamp = {2016.02.24}
}

@InProceedings{Leis2013,
	timestamp = {六 8月 12 20:45:06 2017},
	Title = {The adaptive radix tree: ARTful indexing for main-memory databases},
	Author = {V. Leis and A. Kemper and T. Neumann},
	Booktitle = {Data Engineering (ICDE), 2013 IEEE 29th International Conference on},
	Year = {2013},
	Month = {April},
	Note = {ART},
	Pages = {38-49},
	Doi = {10.1109/ICDE.2013.6544812},
	File = {Leis2013.pdf:Leis2013.pdf:PDF},
	ISSN = {1063-6382},
	Keywords = {cache storage;database indexing;table lookup;tree data structures;tree searching;ART performance;ARTful indexing;RAM;adaptive radix tree;balanced binary search tree;deletion;hash table;in-memory data structure;index structure performance;insertion;internal node;lookup performance;main memory index;main-memory database system;min memory capacity;on-CPU cache utilization;point query;prefix lookup;range scan;read-only search tree;sorted order data;worst-case space consumption;Arrays;Indexing;Subspace constraints;Vegetation}
}

@article{Li2012,
	timestamp = {四 4月 20 11:16:27 2017},
	Author = {Li, Yanni and Wang, Yuping and Bao, Liang},
	Title = {{FACC: A Novel Finite Automaton Based on Cloud Computing for the Multiple
   Longest Common Subsequences Search}},
	Journal = {{MATHEMATICAL PROBLEMS IN ENGINEERING}},
	Year = {2012},
	Abstract = {{Searching for the multiple longest common subsequences (MLCS) has
   significant applications in the areas of bioinformatics, information
   processing, and data mining, and so forth, Although a few parallel MLCS
   algorithms have been proposed, the efficiency and effectiveness of the
   algorithms are not satisfactory with the increasing complexity and size
   of biologic data. To overcome the shortcomings of the existing MLCS
   algorithms, and considering that MapReduce parallel framework of cloud
   computing being a promising technology for cost-effective high
   performance parallel computing, a novel finite automaton (FA) based on
   cloud computing called FACC is proposed under MapReduce parallel
   framework, so as to exploit a more efficient and effective general
   parallel MLCS algorithm. FACC adopts the ideas of matched pairs and
   finite automaton by preprocessing sequences, constructing successor
   tables, and common subsequences finite automaton to search for MLCS.
   Simulation experiments on a set of benchmarks from both real DNA and
   amino acid sequences have been conducted and the results show that the
   proposed FACC algorithm outperforms the current leading parallel MLCS
   algorithm FAST-MLCS.}},
	Publisher = {{HINDAWI PUBLISHING CORPORATION}},
	Address = {{410 PARK AVENUE, 15TH FLOOR, \#287 PMB, NEW YORK, NY 10022 USA}},
	Type = {{Article}},
	Language = {{English}},
	Affiliation = {{Li, YN (Reprint Author), Xidian Univ, Sch Comp Sci \& Technol, Xian 710071, Peoples R China.
   Li, Yanni; Wang, Yuping, Xidian Univ, Sch Comp Sci \& Technol, Xian 710071, Peoples R China.
   Li, Yanni; Bao, Liang, Xidian Univ, Sch Software, Xian 710071, Peoples R China.}},
	DOI = {{10.1155/2012/310328}},
	Article-Number = {{310328}},
	ISSN = {{1024-123X}},
	Keywords-Plus = {{INCREASING SUBSEQUENCES; FAST ALGORITHM; COMPLEXITY; LENGTH}},
	Research-Areas = {{Engineering; Mathematics}},
	Web-of-Science-Categories = {{Engineering, Multidisciplinary; Mathematics, Interdisciplinary
   Applications}},
	Author-Email = {{yannili@mail.xidian.edu.cn}},
	Funding-Acknowledgement = {{National Natural Science Foundation of China {[}61272119]}},
	Funding-Text = {{This work is supported by the National Natural Science Foundation of
   China (no. 61272119).}},
	Number-of-Cited-References = {{26}},
	Times-Cited = {{2}}
}

@inproceedings{Li2016_ICDE,
	timestamp = {四 4月 20 11:16:27 2017},
	Author = {Li, Yanni and Wang, Yuping and Zhang, Zhensong and Wang, Yaxin and Ma,
   Ding and Huang, Jianbin},
	Book-Group-Author = {{IEEE}},
	Title = {{A Novel Fast and Memory Efficient Parallel MLCS Algorithm for Long and
   Large-Scale Sequences Alignments}},
	Booktitle = {{2016 32ND IEEE INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE)}},
	Series = {{IEEE International Conference on Data Engineering}},
	Year = {2016},
	Pages = {{1170-1181}},
	Note = {{32nd IEEE International Conference on Data Engineering (ICDE), Helsinki,
   FINLAND, MAY 16-20, 2016}},
	Organization = {{IEEE; IEEE Comp Soc; Aalto Univ, Sch Sci}},
	Abstract = {{Information usually can be abstracted as a character sequence over a
   finite alphabet. With the advent of the era of big data, the increasing
   length and size of the sequences from various application fields (e.g.,
   biological sequences) result in the classical NP-hard problem, searching
   for the Multiple Longest Common Subsequences of multiple sequences
   (i.e., MLCS problem with many applications in the areas of
   bioinformatics, computational genomics, pattern recognition, etc.),
   becoming a research hotspot and facing severe challenges. In this paper,
   we firstly reveal that the leading dominant-point-based MLCS algorithms
   are very hard to apply to long and large-scale sequences alignments. To
   overcome their defects, based on the proposed problem-solving model and
   parallel topological sorting strategies, we present a novel efficient
   parallel MLCS algorithm. The comprehensive experiments on the benchmark
   datasets of both random and biological sequences demonstrate that both
   the time and space complexities of the proposed algorithm are only
   linearly related to the dominants from aligned sequences, and that the
   proposed algorithm greatly outperforms the existing state-of-the-art
   dominant-point-based MLCS algorithms, and hence it is very suitable for
   long and large-scale sequences alignments.}},
	Publisher = {{IEEE}},
	Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
	Type = {{Proceedings Paper}},
	Language = {{English}},
	Affiliation = {{Li, YN (Reprint Author), Xidian Univ, Sch Software, Xian, Shaanxi, Peoples R China.
   Li, Yanni, Xidian Univ, Sch Software, Xian, Shaanxi, Peoples R China.
   Wang, Yuping, Xidian Univ, Sch Comp Sci \& Technol, Xian, Shaanxi, Peoples R China.
   Zhang, Zhensong, Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
   Wang, Yaxin, Univ Calif Los Angeles, Henry Samueli Sch Engn \& Appl Sci, Los Angeles, CA USA.
   Ma, Ding, Univ Southern Calif, Viterbi Sch Engn, Dept Comp Sci, Los Angeles, CA 90089 USA.
   Huang, Jianbin, Xidian Univ, Sch Software, Xian, Shaanxi, Peoples R China.}},
	ISSN = {{1084-4627}},
	ISBN = {{978-1-5090-2020-1}},
	Keywords = {{Multiple Longest Common Subsequences (MLCS); Irredundant Common
   Subsequence Graph (ICSG); Parallel Collection Chain (PCC); ICSG-PCC
   Model; Parallel Algorithm}},
	Keywords-Plus = {{COMMON SUBSEQUENCES}},
	Research-Areas = {{Computer Science; Engineering}},
	Web-of-Science-Categories = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
	Author-Email = {{yannili@mail.xidian.edu.cn
   ywang@xidian.edu.cn
   zszhang@cse.cuhk.edu.hk
   wangyaxinus@gmail.com
   dingma@usc.edu
   jbhuang@xidian.edu.cn}},
	Number-of-Cited-References = {{19}},
	Times-Cited = {{0}}
}

@inproceedings{Li2016_SIGKDD,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Li, Yanni and Li, Hui and Duan, Tihua and Wang, Sheng and Wang, Zhi and Cheng, Yang},
	title = {A Real Linear and Parallel Multiple Longest Common Subsequences (MLCS) Algorithm},
	booktitle = {Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	series = {KDD '16},
	year = {2016},
	isbn = {978-1-4503-4232-2},
	location = {San Francisco, California, USA},
	pages = {1725--1734},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/2939672.2939842},
	doi = {10.1145/2939672.2939842},
	acmid = {2939842},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {multiple longest common subsequences (mlcs), non-redu-ndant common subsequence graph (ncsg), subsection calculation and serialization, topological sorting}
}

@article{Liu2011,
	timestamp = {三 8月 16 19:06:49 2017},
	title = {DHSWM: An improved multi-pattern matching algorithm based on WM algorithm},
	author = {Liu, W. G. and Hu, Y. G.},
	journal = {Journal of Central South University},
	volume = {42},
	number = {12},
	pages = {3765-3771},
	year = {2011}
}

@book{Louza2015,
	timestamp = {三 8月 16 21:21:54 2017},
	title = {Computing the BWT and the LCP Array in Constant Space},
	author = {Louza, Felipe A. and Telles, Guilherme P.},
	publisher = {Springer International Publishing},
	pages = {312-320},
	year = {2015}
}

@article{Lu2017,
	timestamp = {四 4月 20 11:16:55 2017},
	title = {EXPANDING SPEED OF THE HABITAT FOR A SPECIES IN AN ADVECTIVE ENVIRONMENT.},
	author = {Lu, Junfan and Gu, Hong and Lou, Bendong},
	journal = {Discrete \& Continuous Dynamical Systems-Series B},
	volume = {22},
	number = {2},
	year = {2017}
}

@article{Maier1978,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Maier, David},
	title = {The Complexity of Some Problems on Subsequences and Supersequences},
	journal = {J. ACM},
	issue_date = {April 1978},
	volume = {25},
	number = {2},
	month = apr,
	year = {1978},
	issn = {0004-5411},
	pages = {322--336},
	numpages = {15},
	url = {http://doi.acm.org/10.1145/322063.322075},
	doi = {10.1145/322063.322075},
	acmid = {322075},
	publisher = {ACM},
	address = {New York, NY, USA}
}

@article{Manber1993,
	timestamp = {六 8月 12 17:29:29 2017},
	title = {Suffix arrays: a new method for on-line string searches},
	author = {Manber, Udi and Myers, Gene},
	journal = {siam Journal on Computing},
	volume = {22},
	number = {5},
	pages = {935--948},
	year = {1993},
	publisher = {SIAM}
}

@article{Manzini2004,
	timestamp = {六 8月 12 17:42:04 2017},
	title = {Engineering a lightweight suffix array construction algorithm},
	author = {Manzini, Giovanni and Ferragina, Paolo},
	journal = {Algorithmica},
	volume = {40},
	number = {1},
	pages = {33--50},
	year = {2004},
	publisher = {Springer}
}

@article{Masek1980,
	timestamp = {四 4月 20 11:16:27 2017},
	title = "A faster algorithm computing string edit distances ",
	journal = "Journal of Computer and System Sciences ",
	volume = "20",
	number = "1",
	pages = "18 - 31",
	year = "1980",
	note = "",
	issn = "0022-0000",
	doi = "http://dx.doi.org/10.1016/0022-0000(80)90002-1",
	url = "http://www.sciencedirect.com/science/article/pii/0022000080900021",
	author = "William J. Masek and Michael S. Paterson",
	abstract = "The edit distance between two character strings can be defined as the minimum cost of a sequence of editing operations which transforms one string into the other. The operations we admit are deleting, inserting and replacing one symbol at a time, with possibly different costs for each of these operations. The problem of finding the longest common subsequence of two strings is a special case of the problem of computing edit distances. We describe an algorithm for computing the edit distance between two strings of length n and m, n ⪖ m, which requires O(n · max(1, mlog n)) steps whenever the costs of edit operations are integral multiples of a single positive real number and the alphabet for the strings is finite. These conditions are necessary for the algorithm to achieve the time bound. "
}

@inproceedings{Metwally2016,
	timestamp = {三 8月 16 21:39:39 2017},
	title = {Distributed suffix array construction algorithms: Comparison of two algorithms},
	author = {Metwally, Ahmed A and Kandil, Ahmed H and Abouelhoda, Mohamed},
	booktitle = {Biomedical Engineering Conference (CIBEC), 2016 8th Cairo International},
	pages = {27--30},
	year = {2016},
	organization = {IEEE}
}

@article{Mirarab2015,
	timestamp = {三 8月 16 19:58:42 2017},
	title = {PASTA: Ultra-Large Multiple Sequence Alignment for Nucleotide and Amino-Acid Sequences.},
	author = {Mirarab, S and Nguyen, N and Guo, S. and Wang, L. S. and Kim, J and Warnow, T},
	journal = {Journal of Computational Biology A Journal of Computational Molecular Cell Biology},
	volume = {22},
	number = {5},
	pages = {377},
	year = {2015}
}

@article{Mittal2017,
	timestamp = {四 4月 20 11:16:55 2017},
	Author = {Mittal, Sunil and Kaur, Hardeep and Gautam, Nandini and Mantha, Anil K.},
	Title = {{Biosensors for breast cancer diagnosis: A review of bioreceptors,
   biotransducers and signal amplification strategies}},
	Journal = {{BIOSENSORS \& BIOELECTRONICS}},
	Year = {2017},
	Volume = {{88}},
	Number = {{SI}},
	Pages = {{217-231}},
	Month = {{FEB 15}},
	Note = {{26th Anniversary World Congress on Biosensors (Biosensors), Gothenburg,
   SWEDEN, MAY 24-28, 2016}},
	Organization = {{Ercon Inc}},
	Abstract = {{Breast cancer is highly prevalent in females and accounts for second
   highest number of deaths, worldwide. Cumbersome, expensive and time
   consuming detection techniques presently available for detection of
   breast cancer potentiates the need for development of novel, specific
   and ultrasensitive devices. Biosensors are the promising and selective
   detection devices which hold immense potential as point of care (POC)
   tools. Present review comprehensively scrutinizes various breast cancer
   biosensors developed so far and their technical evaluation with respect
   to efficiency and potency of selected bioreceptors and biotransducers.
   Use of glycoproteins, DNA biomarkers, micro-RNA, circulatory tumor cells
   (CTC) and some potential biomarkers are introduced briefly. The review
   also discusses various strategies used in signal amplification such as
   nanomaterials, redox mediators, p19 protein, duplex specific nucleases
   (DSN) and redox cycling. (C) 2016 Elsevier B.V. All rights reserved.}},
	Publisher = {{ELSEVIER ADVANCED TECHNOLOGY}},
	Address = {{OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON,
   OXFORD OX5 1GB, OXON, ENGLAND}},
	Type = {{Article; Proceedings Paper}},
	Language = {{English}},
	Affiliation = {{Kaur, H (Reprint Author), Cent Univ Punjab, Ctr Environm Sci \& Technol, Bathinda 151001, India.
   Mittal, Sunil; Kaur, Hardeep; Gautam, Nandini, Cent Univ Punjab, Ctr Environm Sci \& Technol, Bathinda 151001, India.
   Mantha, Anil K., Cent Univ Punjab, Ctr Anim Sci, Bathinda 151001, India.}},
	DOI = {{10.1016/j.bios.2016.08.028}},
	ISSN = {{0956-5663}},
	EISSN = {{1873-4235}},
	Keywords = {{Breast cancer; Biomarkers; Nanomaterials; Redox mediators; Redox cycling}},
	Keywords-Plus = {{SURFACE-PLASMON RESONANCE; CIRCULATING TUMOR-CELLS; LABEL-FREE
   DETECTION; ULTRASENSITIVE ELECTROCHEMICAL DETECTION; QUARTZ-CRYSTAL
   MICROBALANCE; HIGHLY SENSITIVE DETECTION; GROWTH-FACTOR RECEPTOR;
   SELF-ASSEMBLED MONOLAYERS; CARBOHYDRATE ANTIGEN 15-3; DUPLEX-SPECIFIC
   NUCLEASE}},
	Research-Areas = {{Biophysics; Biotechnology \& Applied Microbiology; Chemistry;
   Electrochemistry; Science \& Technology - Other Topics}},
	Web-of-Science-Categories = {{Biophysics; Biotechnology \& Applied Microbiology; Chemistry,
   Analytical; Electrochemistry; Nanoscience \& Nanotechnology}},
	Author-Email = {{sunil.cevs@gmail.com
   hardeep\_kaur007@rediffmail.com
   ngautam86@gmail.com
   anilmantha@gmail.com}},
	Number-of-Cited-References = {{184}},
	Times-Cited = {{0}}
}

@article{Moraru2012,
	timestamp = {六 8月 12 20:43:38 2017},
	title = {Exact pattern matching with feed-forward bloom filters},
	author = {Moraru, Iulian and Andersen, David G},
	journal = {Journal of Experimental Algorithmics (JEA)},
	volume = {17},
	pages = {3--4},
	year = {2012},
	publisher = {ACM}
}

@article{Munday2017,
	timestamp = {三 8月 16 19:18:33 2017},
	title = {Detection of DNA sequences from a novel papillomavirus in a feline basal cell carcinoma},
	author = {Munday, John S and French, Adrienne and Thomson, Neroli},
	journal = {Veterinary Dermatology},
	volume = {28},
	number = {2},
	pages = {236},
	year = {2017}
}

@Article{Neuburger2012,
	Title = {Succinct 2D Dictionary Matching},
	Author = {Neuburger, Shoshana and Sokol, Dina},
	Journal = {Algorithmica},
	Year = {2012},
	Number = {3},
	Pages = {662--684},
	Volume = {65},
	Abstract = {The dictionary matching problem seeks all locations in a given text that match any of the patterns in a given dictionary. Efficient algorithms for dictionary matching scan the text once, searching for all patterns simultaneously. Existing algorithms that solve the 2-dimensional dictionary matching problem all require working space proportional to the size of the dictionary.},
	Doi = {10.1007/s00453-012-9615-9},
	File = {Neuburger2012.pdf:Neuburger2012.pdf:PDF},
	ISSN = {1432-0541},
	Owner = {pz},
	Timestamp = {2016.02.24},
	Url = {http://dx.doi.org/10.1007/s00453-012-9615-9}
}

@article{Nong2011,
	timestamp = {六 8月 12 17:49:29 2017},
	title = {Two efficient algorithms for linear time suffix array construction},
	author = {Nong, Ge and Zhang, Sen and Chan, Wai Hong},
	journal = {IEEE Transactions on Computers},
	volume = {60},
	number = {10},
	pages = {1471--1484},
	year = {2011},
	publisher = {IEEE}
}

@article{Nong2013,
	timestamp = {六 8月 12 17:50:22 2017},
	title = {Practical linear-time O (1)-workspace suffix sorting for constant alphabets},
	author = {Nong, Ge},
	journal = {ACM Transactions on Information Systems (TOIS)},
	volume = {31},
	number = {3},
	pages = {15},
	year = {2013},
	publisher = {ACM}
}

@article{Nong2014,
	timestamp = {六 8月 12 17:52:20 2017},
	title = {Suffix array construction in external memory using d-critical substrings},
	author = {Nong, Ge and Chan, Wai Hong and Zhang, Sen and Guan, Xiao Feng},
	journal = {ACM Transactions on Information Systems (TOIS)},
	volume = {32},
	number = {1},
	pages = {1},
	year = {2014},
	publisher = {ACM}
}

@article{Nong2015,
	timestamp = {六 8月 12 17:53:06 2017},
	title = {Induced sorting suffixes in external memory},
	author = {Nong, Ge and Chan, Wai Hong and Hu, Sheng Qing and Wu, Yi},
	journal = {ACM Transactions on Information Systems (TOIS)},
	volume = {33},
	number = {3},
	pages = {12},
	year = {2015},
	publisher = {ACM}
}

@article{Perry2015,
	timestamp = {三 8月 16 19:27:14 2017},
	title = {Insights into hominin phenotypic and dietary evolution from ancient DNA sequence data},
	author = {Perry, G. H. and Kistler, L and Kelaita, M. A. and Sams, A. J.},
	journal = {Journal of Human Evolution},
	volume = {79},
	pages = {55-63},
	year = {2015}
}

@article{Pradhan2016,
	timestamp = {三 8月 16 21:24:49 2017},
	title = {A Comparative Analysis of Compression Techniques – The Sparse Coding and BWT ☆},
	author = {Pradhan, Annapurna and Pati, Nibedita and Rup, Suvendu and Panda, Avipsa S. and Kanoje, Lalit Kumar},
	journal = {Procedia Computer Science},
	volume = {92},
	pages = {106-111},
	year = {2016}
}

@article{Puglisi2007,
	timestamp = {六 8月 12 17:36:15 2017},
	title = {A taxonomy of suffix array construction algorithms},
	author = {Puglisi, Simon J and Smyth, William F and Turpin, Andrew H},
	journal = {acm Computing Surveys (CSUR)},
	volume = {39},
	number = {2},
	pages = {4},
	year = {2007},
	publisher = {ACM}
}

@article{Rajasekaran2014,
	timestamp = {六 8月 12 18:08:30 2017},
	title = {An elegant algorithm for the construction of suffix arrays},
	author = {Rajasekaran, Sanguthevar and Nicolae, Marius},
	journal = {Journal of Discrete Algorithms},
	volume = {27},
	pages = {21--28},
	year = {2014},
	publisher = {Elsevier}
}

@InProceedings{Ramakrishna1997,
	timestamp = {六 8月 12 20:45:34 2017},
	Title = {Performance in Practice of String Hashing Functions},
	Author = {Ramakrishna, M. V. and Zobel, Justin},
	Booktitle = {Proceedings of the Fifth International Conference on Database Systems for Advanced Applications (DASFAA)},
	Year = {1997},
	Note = {Shift-And-Or},
	Pages = {215--224},
	Publisher = {World Scientific Press},
	Acmid = {759509},
	File = {Ramakrishna1997.pdf:Ramakrishna1997.pdf:PDF},
	ISBN = {981-02-3107-5},
	Numpages = {10},
	Url = {http://dl.acm.org/citation.cfm?id=646711.759509}
}

@TECHREPORT{Rick1994,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Claus Rick and Claus Rick and Claus Rick},
	title = {New Algorithms for the Longest Common Subsequence Problem},
	institution = {},
	year = {1994}
}

@article{Sankoff1972,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Sankoff, David},
	title = {Matching Sequences under Deletion/Insertion Constraints},
	volume = {69},
	number = {1},
	pages = {4-6},
	year = {1972},
	abstract = {Given two finite sequences, we wish to find the longest common subsequences satisfying certain deletion/insertion constraints. Consider two successive terms in the desired subsequence. The distance between their positions must be the same in the two original sequences for all but a limited number of such pairs of successive terms. Needleman and Wunsch gave an algorithm for finding longest common subsequences without constraints. This is improved from the viewpoint of computational economy. An economical algorithm is then elaborated for finding subsequences satisfying deletion/insertion constraints. This result is useful in the study of genetic homology based on nucleotide or amino-acid sequences.},
	URL = {http://www.pnas.org/content/69/1/4.abstract},
	eprint = {http://www.pnas.org/content/69/1/4.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@book{Schmidt2016,
	timestamp = {三 8月 16 21:30:18 2017},
	title = {Parallel and space-efficient construction of burrows-wheeler transform and suffix array for big genome data},
	author = {Schmidt, Bertil and Schmidt, Bertil and Schmidt, Bertil},
	publisher = {IEEE Computer Society Press},
	pages = {592},
	year = {2016}
}

@article{Schurmann2007,
	timestamp = {六 8月 12 17:44:17 2017},
	title = {An incomplex algorithm for fast suffix array construction},
	author = {Sch{\"u}rmann, Klaus-Bernd and Stoye, Jens},
	journal = {Software: Practice and Experience},
	volume = {37},
	number = {3},
	pages = {309--329},
	year = {2007},
	publisher = {Wiley Online Library}
}

@inproceedings{Seward2000,
	timestamp = {六 8月 12 17:37:42 2017},
	title = {On the performance of BWT sorting algorithms},
	author = {Seward, Julian},
	booktitle = {Data Compression Conference, 2000. Proceedings. DCC 2000},
	pages = {173--182},
	year = {2000},
	organization = {IEEE}
}

@article{Smith1981,
	timestamp = {四 4月 20 11:16:27 2017},
	title = "Identification of common molecular subsequences",
	journal = "Journal of Molecular Biology",
	volume = "147",
	number = "1",
	pages = "195 - 197",
	year = "1981",
	note = "",
	issn = "0022-2836",
	doi = "http://dx.doi.org/10.1016/0022-2836(81)90087-5",
	url = "http://www.sciencedirect.com/science/article/pii/0022283681900875",
	author = "T.F. Smith and M.S. Waterman",
	abstract = ""
}

@book{Strate2015,
	timestamp = {三 8月 16 20:59:05 2017},
	title = {Full-Text Indexing},
	author = {Strate, Jason and Fritchey, Grant},
	publisher = {Apress},
	year = {2015}
}

@inproceedings{Tan2011,
	timestamp = {三 8月 16 19:13:21 2017},
	title = {Speeding up pattern matching by optimal partial string extraction},
	author = {Tan, Jianlong and Xia, Liu and Liu, Yanbing and Ping, Liu},
	booktitle = {Computer Communications Workshops},
	pages = {1030-1035},
	year = {2011}
}

@article{Tang2015,
	timestamp = {六 8月 12 20:32:49 2017},
	title = {Document representation with statistical word senses in cross-lingual document clustering},
	author = {Tang, Guoyu and Xia, Yunqing and Cambria, Erik and Jin, Peng and Zheng, Thomas Fang},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	volume = {29},
	number = {02},
	pages = {1559003},
	year = {2015},
	publisher = {World Scientific}
}

@InProceedings{Tuck2004,
	timestamp = {六 8月 12 20:33:28 2017},
	Title = {Deterministic memory-efficient string matching algorithms for intrusion detection},
	Author = {N. Tuck and T. Sherwood and B. Calder and G. Varghese},
	Booktitle = {INFOCOM 2004. Twenty-third AnnualJoint Conference of the IEEE Computer and Communications Societies},
	Year = {2004},
	Month = {March},
	Pages = {2628-2639 vol.4},
	Volume = {4},
	Doi = {10.1109/INFCOM.2004.1354682},
	File = {Tuck2004.pdf:Tuck2004.pdf:PDF},
	ISSN = {0743-166X},
	Keywords = {Internet;performance evaluation;security of data;string matching;Aho-Corasick string-matching algorithm;Internet;deterministic memory-efficient string matching algorithm;intrusion detection system;worst-case performance;Computer crime;Computer science;Hardware;Internet;Intrusion detection;Power engineering and energy;Protection;Software performance;Telecommunication traffic;Web server}
}

@article{Wang2011,
	timestamp = {四 4月 20 11:16:27 2017},
	Author = {Wang, Qingguo and Korkin, Dmitry and Shang, Yi},
	Title = {{A Fast Multiple Longest Common Subsequence (MLCS) Algorithm}},
	Journal = {{IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING}},
	Year = {2011},
	Volume = {{23}},
	Number = {{3}},
	Pages = {{321-334}},
	Month = {{MAR}},
	Abstract = {{Finding the longest common subsequence (LCS) of multiple strings is an
   NP-hard problem, with many applications in the areas of bioinformatics
   and computational genomics. Although significant efforts have been made
   to address the problem and its special cases, the increasing complexity
   and size of biological data require more efficient methods applicable to
   an arbitrary number of strings. In this paper, we present a new
   algorithm for the general case of multiple LCS (or MLCS) problem, i.e.,
   finding an LCS of any number of strings, and its parallel realization.
   The algorithm is based on the dominant point approach and employs a fast
   divide-and-conquer technique to compute the dominant points. When
   applied to a case of three strings, our algorithm demonstrates the same
   performance as the fastest existing MLCS algorithm designed for that
   specific case. When applied to more than three strings, our algorithm is
   significantly faster than the best existing sequential methods, reaching
   up to 2-3 orders of magnitude faster speed on large-size problems.
   Finally, we present an efficient parallel implementation of the
   algorithm. Evaluating the parallel algorithm on a benchmark set of both
   random and biological sequences reveals a near-linear speedup with
   respect to the sequential algorithm.}},
	Publisher = {{IEEE COMPUTER SOC}},
	Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
	Type = {{Article}},
	Language = {{English}},
	Affiliation = {{Wang, QG (Reprint Author), Univ Missouri, Dept Comp Sci, 207 Engn Bldg W, Columbia, MO 65211 USA.
   Wang, Qingguo; Korkin, Dmitry; Shang, Yi, Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
   Korkin, Dmitry, Univ Missouri, Inst Informat, Columbia, MO 65211 USA.}},
	DOI = {{10.1109/TKDE.2010.123}},
	ISSN = {{1041-4347}},
	EISSN = {{1558-2191}},
	Keywords = {{Longest common subsequence (LCS); multiple longest common subsequence
   (MLCS); dynamic programming; dominant point method; divide and conquer;
   parallel processing; multithreading}},
	Keywords-Plus = {{EFFICIENT PARALLEL ALGORITHMS; SEQUENCE MOTIFS; STRINGS; MAXIMA; LENGTH;
   PFAM; SET}},
	Research-Areas = {{Computer Science; Engineering}},
	Web-of-Science-Categories = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical \& Electronic}},
	Author-Email = {{qwp4b@mail.missouri.edu
   korkin@korkinlab.org
   shangy@missouri.edu}},
	ORCID-Numbers = {{Wang, Qingguo/0000-0002-5125-3724}},
	Funding-Acknowledgement = {{Shumaker Endowment in Bioinformatics; NIH {[}5R21GM078601-02]; US
   National Science Foundation (NSF) {[}DBI-0845196]}},
	Funding-Text = {{This research was supported in part by the Shumaker Endowment in
   Bioinformatics and NIH Grant 5R21GM078601-02. D. Korkin acknowledges
   funding from the US National Science Foundation (NSF) grant DBI-0845196.
   The authors are also grateful to the authors of FAST-LCS for sharing
   with them its code.}},
	Number-of-Cited-References = {{50}},
	Times-Cited = {{9}}
}

@Misc{Wu1994,
	Title = {A Fast Algorithm For Multi-Pattern Searching},
	Author = {Sun Wu and Udi Manber},
	Note = {WM},
	Year = {1994},
	File = {Wu1994.pdf:Wu1994.pdf:PDF}
}

@article{Xiao2016,
	timestamp = {六 8月 12 20:48:42 2017},
	title = {Queueing analysis of continuous queries for uncertain data streams over sliding windows},
	author = {Xiao, Guoqing and Li, Kenli and Zhou, Xu and Li, Keqin},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	volume = {30},
	number = {09},
	pages = {1660001},
	year = {2016},
	publisher = {World Scientific}
}

@article{Xue2015,
	timestamp = {六 8月 12 20:50:33 2017},
	Author = {Xue, Xingsi and Wang, Yuping},
	Title = {{Optimizing ontology alignments through a Memetic Algorithm using both
   MatchFmeasure and Unanimous Improvement Ratio}},
	Journal = {{ARTIFICIAL INTELLIGENCE}},
	Year = {2015},
	Volume = {{223}},
	Pages = {{65-81}},
	Month = {{JUN}},
	Abstract = {{There are three main drawbacks of current evolutionary approaches for
   determining the weights of ontology matching system. The first drawback
   is that it is difficult to simultaneously deal with several pairs of
   ontologies, i.e. finding a universal weight configuration that can be
   used for different ontology pairs without adjustment. The second one is
   that a reference alignment between two ontologies to be aligned should
   be given in advance which could be very expensive to obtain especially
   when the scale of ontologies is considerably large. The last one arises
   from f-measure, a generally used evaluation metric of the alignment's
   quality, which may cause the bias improvement of the solution. To
   overcome these three defects, in this paper, we propose to use both
   MatchFmeasure, a rough evaluation metric on no reference alignment to
   approximate f-measure, and Unanimous Improvement Ratio (UIR), a measure
   that complements MatchFmeasure, in the process of optimizing the
   ontology alignments by Memetic Algorithm (MA). The experimental results
   have shown that the MA using both MatchFmeasure and UIR is effective to
   simultaneously align multiple pairs of ontologies and avoid the bias
   improvement caused by MatchFeasure. Moreover, the comparison with
   state-of-the-art ontology matching systems further indicates the
   effectiveness of the proposed method. (C) 2015 Elsevier B.V. All rights
   reserved.}},
	Publisher = {{ELSEVIER SCIENCE BV}},
	Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
	Type = {{Article}},
	Language = {{English}},
	Affiliation = {{Wang, YP (Reprint Author), Xidian Univ, Sch Comp Sci \& Technol, Xian, Shaanxi, Peoples R China.
   Xue, Xingsi; Wang, Yuping, Xidian Univ, Sch Comp Sci \& Technol, Xian, Shaanxi, Peoples R China.
   Xue, Xingsi, Fujian Univ Technol, Sch Informat Sci \& Engn, Fuzhou, Fujian, Peoples R China.}},
	DOI = {{10.1016/j.artint.2015.03.001}},
	ISSN = {{0004-3702}},
	EISSN = {{1872-7921}},
	Keywords = {{Ontology alignment; Memetic Algorithm; MatchFmeasure; Unanimous
   Improvement Ratio}},
	Research-Areas = {{Computer Science}},
	Web-of-Science-Categories = {{Computer Science, Artificial Intelligence}},
	Author-Email = {{ywang@xidian.edu.cn}},
	Funding-Acknowledgement = {{National Natural Science Foundation of China {[}61272119, 61472297]}},
	Funding-Text = {{This work was supported by the National Natural Science Foundation of
   China (No. 61272119 and No. 61472297).}},
	Number-of-Cited-References = {{29}},
	Times-Cited = {{3}}
}

@article{Xue2016,
	timestamp = {六 8月 12 20:50:43 2017},
	Author = {Xue, Xingsi and Wang, Yuping},
	Title = {{Using Memetic Algorithm for Instance Coreference Resolution}},
	Journal = {{IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING}},
	Year = {2016},
	Volume = {{28}},
	Number = {{2}},
	Pages = {{580-591}},
	Month = {{FEB 1}},
	Note = {{IEEE 30th International Conference on Data Engineering (ICDE), Chicago,
   IL, MAR 31-APR 04, 2014}},
	Organization = {{IEEE; Microsoft; Qatar Comp Res Inst; HERE Nokia; Purdue Univ, Cyber
   Ctr; NW Univ, McCormick Sch Engn; Google}},
	Abstract = {{Instance coreference resolution is an essential problem in studying
   semantic web, and it is also critical for the implementation of web of
   data and future integration and application of semantic data. In this
   paper, we propose to use Memetic Algorithm (MA) to solve this instance
   coreference problem in a sequential stage, i.e., the instance-level
   matching is carried out with the result of schema-level matching. We
   first give the optimization model for schema-level matching and
   instance-level matching. Then, we, respectively, present profile
   similarity measures and the rough evaluation metrics with the assumption
   that the golden alignment for both schema-level matching and
   instance-level matching is one-to-one. Furthermore, we give the details
   of the MA. Finally, the experiments of comparing our approach with the
   state-of-the-art systems on OAEI benchmarks and real-world datasets are
   conducted and the results demonstrate that our approach is effective.}},
	Publisher = {{IEEE COMPUTER SOC}},
	Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
	Type = {{Article; Proceedings Paper}},
	Language = {{English}},
	Affiliation = {{Xue, XS; Wang, YP (Reprint Author), Xidian Univ, Sch Comp Sci \& Technol, Xian, Shaanxi, Peoples R China.
   Xue, XS (Reprint Author), Fujian Univ Technol, Sch Informat Sci \& Engn, Fuzhou, Fujian, Peoples R China.
   Xue, Xingsi; Wang, Yuping, Xidian Univ, Sch Comp Sci \& Technol, Xian, Shaanxi, Peoples R China.
   Xue, Xingsi, Fujian Univ Technol, Sch Informat Sci \& Engn, Fuzhou, Fujian, Peoples R China.}},
	DOI = {{10.1109/TKDE.2015.2475755}},
	ISSN = {{1041-4347}},
	EISSN = {{1558-2191}},
	Keywords = {{Instance coreference resolution; memetic algorithm; profile similarity
   measure}},
	Keywords-Plus = {{ONTOLOGY ALIGNMENT}},
	Research-Areas = {{Computer Science; Engineering}},
	Web-of-Science-Categories = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical \& Electronic}},
	Author-Email = {{jack8375@gmail.com
   ywang@xidian.edu.cn}},
	Funding-Acknowledgement = {{National Natural Science Foundation of China {[}61272119, 61472297,
   61503082]; Fundamental Research Funds for the Central Universities
   {[}BDZ021430]}},
	Funding-Text = {{This work was supported by the National Natural Science Foundation of
   China (Nos. 61272119, 61472297 and 61503082) and the Fundamental
   Research Funds for the Central Universities (Nos. BDZ021430).}},
	Number-of-Cited-References = {{44}},
	Times-Cited = {{0}}
}

@article{Yan2016,
	timestamp = {六 8月 12 20:50:21 2017},
	title = {Combining Renyi Entropy and EWMA to Detect Common Attacks in Network},
	author = {Yan, Ruoyu},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	volume = {30},
	number = {10},
	pages = {1650021},
	year = {2016},
	publisher = {World Scientific}
}

@inproceedings{Yang2010,
	timestamp = {四 4月 20 11:16:27 2017},
	title = {An efficient parallel algorithm for longest common subsequence problem on GPUs},
	author = {Yang, Jiaoyun and Xu, Yun and Shang, Yi},
	booktitle = {Proceedings of the world congress on engineering, WCE},
	volume = {1},
	year = {2010}
}

@ARTICLE{Yang2013,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {J. Yang and Y. Xu and G. Sun and Y. Shang},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	title = {A New Progressive Algorithm for a Multiple Longest Common Subsequences Problem and Its Efficient Parallelization},
	year = {2013},
	volume = {24},
	number = {5},
	pages = {862-870},
	abstract = {The multiple longest common subsequence (MLCS) problem, which is related to the measurement of sequence similarity, is one of the fundamental problems in many fields. As an NP-hard problem, finding a good approximate solution within a reasonable time is important for solving large-size problems in practice. In this paper, we present a new progressive algorithm, Pro-MLCS, based on the dominant point approach. Pro-MLCS can find an approximate solution quickly and then progressively generate better solutions until obtaining the optimal one. Pro-MLCS employs three new techniques: 1) a new heuristic function for prioritizing candidate points; 2) a novel $(d)$-index-tree data structure for efficient computation of dominant points; and 3) a new pruning method using an upper bound function and approximate solutions. Experimental results show that Pro-MLCS can obtain the first approximate solution almost instantly and needs only a very small fraction, e.g., 3 percent, of the entire running time to get the optimal solution. Compared to existing state-of-the-art algorithms, Pro-MLCS can find better solutions in much shorter time, one to two orders of magnitude faster. In addition, two parallel versions of Pro-MLCS are developed: DPro-MLCS for distributed memory architecture and DSDPro-MLCS for hierarchical distributed shared memory architecture. Both parallel algorithms can efficiently utilize parallel computing resources and achieve nearly linear speedups. They also have a desirable progressiveness property&#x2014;finding better solutions in shorter time when given more hardware resources.},
	keywords = {Approximation algorithms;Complexity theory;DNA;Data structures;Heuristic algorithms;Memory architecture;Parallel algorithms;Multiple longest common subsequence problem (MLCS);SMP cluster;branch-and-bound search;distributed memory architecture;progressive algorithm;skyline problem},
	doi = {10.1109/TPDS.2012.202},
	ISSN = {1045-9219},
	month = {May}
}

@ARTICLE{Yang2014,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {J. Yang and Y. Xu and Y. Shang and G. Chen},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	title = {A Space-Bounded Anytime Algorithm for the Multiple Longest Common Subsequence Problem},
	year = {2014},
	volume = {26},
	number = {11},
	pages = {2599-2609},
	abstract = {The multiple longest common subsequence (MLCS) problem, related to the identification of sequence similarity, is an important problem in many fields. As an NP-hard problem, its exact algorithms have difficulty in handling large-scale data and timeand space-efficient algorithms are required in real-world applications. To deal with time constraints, anytime algorithms have been proposed to generate good solutions with a reasonable time. However, there exists little work on space-efficient MLCS algorithms. In this paper, we formulate the MLCS problem into a graph search problem and present two space-efficient anytime MLCS algorithms, SA-MLCS and SLA-MLCS. SA-MLCS uses an iterative beam widening search strategy to reduce space usage during the iterative process of finding better solutions. Based on SA-MLCS, SLA-MLCS, a space-bounded algorithm, is developed to avoid space usage from exceeding available memory. SLA-MLCS uses a replacing strategy when SA-MLCS reaches a given space bound. Experimental results show SA-MLCS and SLA-MLCS use an order of magnitude less space and time than the state-of-the-art approximate algorithm MLCS-APP while finding better solutions. Compared to the state-of-the-art anytime algorithm Pro-MLCS, SA-MLCS and SLA-MLCS can solve an order of magnitude larger size instances. Furthermore, SLA-MLCS can find much better solutions than SA-MLCS on large size instances.},
	keywords = {approximation theory;computational complexity;data handling;graph theory;iterative methods;optimisation;search problems;MLCS-APP;NP-hard problem;SA-MLCS;SLA-MLCS;approximate algorithm;graph search problem;iterative beam widening search strategy;large-scale data handling;multiple longest common subsequence problem;replacing strategy;sequence similarity identification;space bounded anytime algorithm;space efficient anytime MLCS algorithm;space usage reduction;time constraint;time efficient algorithm;Algorithm design and analysis;Approximation algorithms;Dynamic programming;Educational institutions;Heuristic algorithms;Memory management;Search problems;Heuristic search;anytime algorithm;multiple longest common subsequence (MLCS);space bounded},
	doi = {10.1109/TKDE.2014.2304464},
	ISSN = {1041-4347},
	month = {Nov}
}

@article{Yuan2013,
	timestamp = {三 8月 16 19:08:44 2017},
	author = {Zhenlong Yuan, and Baohua Yang, and Xiaoqi Ren, and Yibo Xue, },
	title = {TFD: A multi-pattern matching algorithm for large-scale URL filtering},
	journal = {2013 International Conference on Computing, Networking and Communications (ICNC 2013)},
	volume = {00},
	number = {},
	issn = {},
	year = {2013},
	pages = {359-363},
	doi = {doi.ieeecomputersociety.org/10.1109/ICCNC.2013.6504109},
	publisher = {IEEE Computer Society},
	address = {Los Alamitos, CA, USA}
}

@InProceedings{Zhan2014,
	Title = {An Improved Multi-pattern Matching Algorithm for Large-Scale Pattern Sets},
	Author = {P. Zhan and W. Yuping and X. Jinfeng},
	Booktitle = {Computational Intelligence and Security (CIS), 2014 Tenth International Conference on},
	Year = {2014},
	Month = {Nov},
	Note = {my},
	Pages = {197-200},
	Abstract = {Multi-pattern matching algorithms are broadly used in many fields of computer science. However, the performance of the existing algorithms seriously degrades with the increasing of the number of patterns. In this paper, an improved multi-pattern matching algorithm based on the framework of the Wu-Manber (WM) algorithm is proposed to effectively deal with the large pattern sets. The WM algorithm is improved in two aspects. Firstly, the lengths of lists in the HASH table are balanced to reduce the number of candidate patterns, Secondly, a data structure called the "INDEX table" based on binary search is designed to reduce the time for finding candidate patterns. Experimental results show that our algorithm is efficient for large-scale pattern sets.},
	Doi = {10.1109/CIS.2014.136},
	File = {Zhan2014.pdf:Zhan2014.pdf:PDF},
	Keywords = {data structures;image matching;WM algorithm;Wu-Manber algorithm;binary search;computer science;data structure;hash table;improved multipattern matching algorithm;index table;large-scale pattern sets;Algorithm design and analysis;Computer science;Educational institutions;Indexes;Pattern matching;Security;Time complexity;Wu-Manber algorithm;multi-pattern matching;string matching}
}

@InProceedings{Zhang2009a,
	timestamp = {六 8月 12 20:38:37 2017},
	Title = {High Concurrence Wu-Manber Multiple Patterns Matching Algorithm},
	Author = {Baojun Zhang and Xiaoping Chen and Xuezeng Pan and Zhaohui Wu},
	Year = {2009},
	Month = {August},
	File = {Zhang2009.pdf:Zhang2009.pdf:PDF}
}

@inproceedings{Zhang2009b,
	timestamp = {三 8月 16 19:11:04 2017},
	title = {Address Filtering Based Wu-Manber Multiple Patterns Matching Algorithm},
	author = {Zhang, Baojun and Chen, Xiaoping and Ping, Lingdi and Wu, Zhaohui},
	booktitle = {Second International Workshop on Computer Science and Engineering},
	pages = {408-412},
	year = {2009}
}

@Article{Zhang2015,
	timestamp = {六 8月 12 20:42:16 2017},
	Title = {An efficient parallel algorithm for exact multi-pattern matching},
	Author = {Zhang, Hongli and Xu, Dongliang and Tian, Zhihong and Fan, Yujian},
	Journal = {SECURITY AND COMMUNICATION NETWORKS},
	Year = {2015},
	Month = {JUN},
	Note = {PEBF},
	Number = {9},
	Pages = {1688-1697},
	Volume = {8},
	Abstract = {This paper presents a parallel algorithm Parallel Extended Bloom Filter (PEBF) for exact multi-pattern matching based on Bloom filter. To improve the throughput and parallelism of the algorithm, we divided the pattern set into N subsets where the length of patterns is the same, and different subsets would not intersect each other. We construct an EBF for each subset and use N threads to simultaneously process the subsets in parallel. We implement our solution on the graphics processing unit, called G-PEBF. Experimental results demonstrate that PEBF performs better than the Wu-Manber (WM) algorithm in terms of time and space. And G-PEBF outperforms the G-WM (WM algorithm implemented on graphics processing unit). The speedup of G-PEBF is up to 60 times at peak performance and almost 10 times at worst performance to the PEBF algorithm. Copyright (c) 2014 John Wiley \& Sons, Ltd.},
	Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
	Affiliation = {Xu, DL (Reprint Author), Harbin Inst Technol, Sch Comp Sci \& Technol, Harbin 150006, Peoples R China. Zhang, Hongli; Xu, Dongliang; Tian, Zhihong; Fan, Yujian, Harbin Inst Technol, Sch Comp Sci \& Technol, Harbin 150006, Peoples R China.},
	Doi = {10.1002/sec.1115},
	Eissn = {1939-0122},
	File = {Zhang2015.pdf:Zhang2015.pdf:PDF},
	ISSN = {1939-0114},
	Keywords = {multi-pattern matching; parallel matching; Bloom Filter; GPU},
	Language = {English},
	Publisher = {WILEY-BLACKWELL},
	Type = {Article}
}

@article{Zhang2016,
	timestamp = {六 8月 12 20:29:49 2017},
	title = {A new feature selection approach to naive Bayes text classifiers},
	author = {Zhang, Lungan and Jiang, Liangxiao and Li, Chaoqun},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	volume = {30},
	number = {02},
	pages = {1650003},
	year = {2016},
	publisher = {World Scientific}
}

@InBook{Zhou2007,
	timestamp = {六 8月 12 20:00:06 2017},
	Title = {Information and Communications Security: 9th International Conference, ICICS 2007, Zhengzhou, China, December 12-15, 2007. Proceedings},
	Author = {Zhou, Zongwei and Xue, Yibo and Liu, Junda and Zhang, Wei and Li, Jun},
	Chapter = {MDH: A High Speed Multi-phase Dynamic Hash String Matching Algorithm for Large-Scale Pattern Set},
	Editor = {Qing, Sihan and Imai, Hideki and Wang, Guilin},
	Pages = {201--215},
	Publisher = {Springer Berlin Heidelberg},
	Year = {2007},
	Address = {Berlin, Heidelberg},
	Doi = {10.1007/978-3-540-77048-0_16},
	File = {Zhou2007.pdf:Zhou2007.pdf:PDF},
	ISBN = {978-3-540-77048-0},
	Url = {http://dx.doi.org/10.1007/978-3-540-77048-0_16}
}

@article{Zou2015,
	timestamp = {三 8月 16 19:57:53 2017},
	title = {HAlign: Fast multiple similar DNA/RNA sequence alignment based on the centre star strategy},
	author = {Zou, Q. and Hu, Q. and Guo, M. and Wang, G.},
	journal = {Bioinformatics},
	volume = {31},
	number = {15},
	pages = {2475},
	year = {2015}
}

@Book{Zvelebil2007,
	year = {2007},
	publisher = {Garland Science},
	title = {Understanding bioinformatics},
	author = {M. Zvelebil and J. Baum},
	timestamp = {二 6月 27 16:02:01 2017}
}

@techreport{korkin2001,
	timestamp = {四 4月 20 11:16:27 2017},
	title = {A new dominant point-based parallel algorithm for multiple longest common subsequence problem},
	author = {Korkin, Dmitry},
	year = {2001},
	institution = {Technical report, Department of Computer Science, University of New Brunswick, NB Canada}
}

