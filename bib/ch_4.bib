
@article{Apostolico1992,
	timestamp = {四 4月 20 11:16:27 2017},
	title = "Fast linear-space computations of longest common subsequences ",
	journal = "Theoretical Computer Science ",
	volume = "92",
	number = "1",
	pages = "3 - 17",
	year = "1992",
	note = "",
	issn = "0304-3975",
	doi = "http://dx.doi.org/10.1016/0304-3975(92)90132-Y",
	url = "http://www.sciencedirect.com/science/article/pii/030439759290132Y",
	author = "A. Apostolico and S. Browne and C. Guerra",
	abstract = "Space saving techniques in computations of a longest common subsequence (LCS) of two strings are crucial in many applications, notably, in molecular sequence comparisons. For about ten years, however, the only linear-space \{LCS\} algorithm known required time quadratic in the length of the input, for all inputs. This paper reviews linear-space \{LCS\} computations in connection with two classical paradigms originally designed to take less than quadratic time in favorable circumstances. The objective is to achieve the space reduction without alteration of the asymptotic time complexity of the original algorithm. The first one of the resulting constructions takes time O(n(m−l)), and is thus suitable for cases where the \{LCS\} is expected to be close to the shortest input string. The second takes time O(ml log(min[s, m, 2nl])) and suits cases where one of the inputs is much shorter than the other. Here m and n (m⩽n) are the lengths of the two input strings, l is the length of the longest common subsequences and s is the size of the alphabet. Along the way, a very simple O(m(m−l)) time algorithm is also derived for the case of strings of equal length. "
}

@Article{Aravanis2017,
	doi = {10.1016/j.cell.2017.01.030},
	pages = {571-574},
	number = {4},
	volume = {168},
	year = {2017},
	journal = {Cell},
	title = {Next-Generation Sequencing of Circulating Tumor DNA for Early Cancer Detection},
	author = { Alexander M. Aravanis, Mark Lee, Richard, D. Klausner},
	timestamp = {二 6月 27 16:01:37 2017}
}

@article{Chen2006,
	timestamp = {四 4月 20 11:16:27 2017},
	Author = {Chen, Yixin and Wan, Andrew and Liu, Wei},
	Title = {{A fast parallel algorithm for finding the longest common sequence of
   multiple biosequences}},
	Journal = {{BMC BIOINFORMATICS}},
	Year = {2006},
	Volume = {{7}},
	Number = {{4}},
	Note = {{Symposium of Computations in Bioinformatics and Bioscience in
   Conjunction with the International Mult-Symposium on Computer and
   Computational Sciences, Hangzhou, PEOPLES R CHINA, JUN 20-24, 2006}},
	Abstract = {{Background: Searching for the longest common sequence (LCS) of multiple
   biosequences is one of the most fundamental tasks in bioinformatics. In
   this paper, we present a parallel algorithm named FAST\_LCS to speedup
   the computation for finding LCS.
   Results: A fast parallel algorithm for LCS is presented. The algorithm
   first constructs a novel successor table to obtain all the identical
   pairs and their levels. It then obtains the LCS by tracing back from the
   identical character pairs at the last level. Effective pruning
   techniques are developed to significantly reduce the computational
   complexity. Experimental results on gene sequences in the tigr database
   show that our algorithm is optimal and much more efficient than other
   leading LCS algorithms.
   Conclusion: We have developed one of the fastest parallel LCS algorithms
   on an MPP parallel computing model. For two sequences X and Y with
   lengths n and m, respectively, the memory required is max\{4{*}(n+ 1)+
   4{*}(m+ 1), L\}, where L is the number of identical character pairs. The
   time complexity is O(L) for sequential execution, and O(vertical bar
   LCS(X, Y)vertical bar) for parallel execution, where vertical bar LCS(X,
   Y)vertical bar is the length of the LCS of X and Y. For n sequences X-1,
   X-2, ..., X-n, the time complexity is O(L) for sequential execution, and
   O(vertical bar LCS(X-1, X-2,..., X-n)vertical bar) for parallel
   execution. Experimental results support our analysis by showing
   significant improvement of the proposed method over other leading LCS
   algorithms.}},
	Publisher = {{BIOMED CENTRAL LTD}},
	Address = {{MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND}},
	Type = {{Article; Proceedings Paper}},
	Language = {{English}},
	Affiliation = {{Chen, YX (Reprint Author), Washington Univ, Dept Comp Sci \& Engn, St Louis, MO 63130 USA.
   Washington Univ, Dept Comp Sci \& Engn, St Louis, MO 63130 USA.
   Yangzhou Univ, Dept Comp Sci, Yangzhou 225009, Peoples R China.}},
	DOI = {{10.1186/1471-2105-7-S4-S4}},
	Article-Number = {{S4}},
	ISSN = {{1471-2105}},
	Keywords-Plus = {{SUBSEQUENCE PROBLEM; ALIGNMENT; ARRAY; SEARCH; TOOL}},
	Research-Areas = {{Biochemistry \& Molecular Biology; Biotechnology \& Applied
   Microbiology; Mathematical \& Computational Biology}},
	Web-of-Science-Categories = {{Biochemical Research Methods; Biotechnology \& Applied Microbiology;
   Mathematical \& Computational Biology}},
	Author-Email = {{chen@cse.wustl.edu
   awan@wustl.edu
   yzliuwei@126.com}},
	Number-of-Cited-References = {{29}},
	Times-Cited = {{8}}
}

@article{Hirschberg1977,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Hirschberg, Daniel S.},
	title = {Algorithms for the Longest Common Subsequence Problem},
	journal = {J. ACM},
	issue_date = {Oct. 1977},
	volume = {24},
	number = {4},
	month = oct,
	year = {1977},
	issn = {0004-5411},
	pages = {664--675},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/322033.322044},
	doi = {10.1145/322033.322044},
	acmid = {322044},
	publisher = {ACM},
	address = {New York, NY, USA}
}

@Article{Hsu1984,
	timestamp = {四 4月 20 11:16:27 2017},
	author = "Hsu, W. J.
and Du, M. W.",
	title = "Computing a longest common subsequence for a set of strings",
	journal = "BIT Numerical Mathematics",
	year = "1984",
	volume = "24",
	number = "1",
	pages = "45--59",
	abstract = "The known 2-string LCS problem is generalized to finding a Longest Common Subsequence (LCS) for a set of strings. A new, general approach that systematically enumerates common subsequences is proposed for the solution. Assuming a finite symbol set, it is shown that the presented scheme requires a preprocessing time that grows linearly with the total length of the input strings and a processing time that grows linearly with (K), the number of strings, and (∥ℙ∥) the number of matches among them. The only previous algorithm for the generalized LCS problem takesO(K{\textperiodcentered}|S1|{\textperiodcentered}|S2|{\textperiodcentered}...|S                  k                |) execution time, where |S                  i                | denotes the length of the stringS                  i                . Since typically ∥ℙ∥ is a very small percentage of |S1|{\textperiodcentered}|S2|{\textperiodcentered}...{\textperiodcentered}|S                  k                |, the proposed method may be considered to be much more efficient than the straightforward dynamic programming approach.",
	issn = "1572-9125",
	doi = "10.1007/BF01934514",
	url = "http://dx.doi.org/10.1007/BF01934514"
}

@article{Hunt1977,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Hunt, James W. and Szymanski, Thomas G.},
	title = {A Fast Algorithm for Computing Longest Common Subsequences},
	journal = {Commun. ACM},
	issue_date = {May 1977},
	volume = {20},
	number = {5},
	month = may,
	year = {1977},
	issn = {0001-0782},
	pages = {350--353},
	numpages = {4},
	url = {http://doi.acm.org/10.1145/359581.359603},
	doi = {10.1145/359581.359603},
	acmid = {359603},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {efficient algorithms, longest common subsequence}
}

@article{Li2012,
	timestamp = {四 4月 20 11:16:27 2017},
	Author = {Li, Yanni and Wang, Yuping and Bao, Liang},
	Title = {{FACC: A Novel Finite Automaton Based on Cloud Computing for the Multiple
   Longest Common Subsequences Search}},
	Journal = {{MATHEMATICAL PROBLEMS IN ENGINEERING}},
	Year = {2012},
	Abstract = {{Searching for the multiple longest common subsequences (MLCS) has
   significant applications in the areas of bioinformatics, information
   processing, and data mining, and so forth, Although a few parallel MLCS
   algorithms have been proposed, the efficiency and effectiveness of the
   algorithms are not satisfactory with the increasing complexity and size
   of biologic data. To overcome the shortcomings of the existing MLCS
   algorithms, and considering that MapReduce parallel framework of cloud
   computing being a promising technology for cost-effective high
   performance parallel computing, a novel finite automaton (FA) based on
   cloud computing called FACC is proposed under MapReduce parallel
   framework, so as to exploit a more efficient and effective general
   parallel MLCS algorithm. FACC adopts the ideas of matched pairs and
   finite automaton by preprocessing sequences, constructing successor
   tables, and common subsequences finite automaton to search for MLCS.
   Simulation experiments on a set of benchmarks from both real DNA and
   amino acid sequences have been conducted and the results show that the
   proposed FACC algorithm outperforms the current leading parallel MLCS
   algorithm FAST-MLCS.}},
	Publisher = {{HINDAWI PUBLISHING CORPORATION}},
	Address = {{410 PARK AVENUE, 15TH FLOOR, \#287 PMB, NEW YORK, NY 10022 USA}},
	Type = {{Article}},
	Language = {{English}},
	Affiliation = {{Li, YN (Reprint Author), Xidian Univ, Sch Comp Sci \& Technol, Xian 710071, Peoples R China.
   Li, Yanni; Wang, Yuping, Xidian Univ, Sch Comp Sci \& Technol, Xian 710071, Peoples R China.
   Li, Yanni; Bao, Liang, Xidian Univ, Sch Software, Xian 710071, Peoples R China.}},
	DOI = {{10.1155/2012/310328}},
	Article-Number = {{310328}},
	ISSN = {{1024-123X}},
	Keywords-Plus = {{INCREASING SUBSEQUENCES; FAST ALGORITHM; COMPLEXITY; LENGTH}},
	Research-Areas = {{Engineering; Mathematics}},
	Web-of-Science-Categories = {{Engineering, Multidisciplinary; Mathematics, Interdisciplinary
   Applications}},
	Author-Email = {{yannili@mail.xidian.edu.cn}},
	Funding-Acknowledgement = {{National Natural Science Foundation of China {[}61272119]}},
	Funding-Text = {{This work is supported by the National Natural Science Foundation of
   China (no. 61272119).}},
	Number-of-Cited-References = {{26}},
	Times-Cited = {{2}}
}

@inproceedings{Li2016_ICDE,
	timestamp = {四 4月 20 11:16:27 2017},
	Author = {Li, Yanni and Wang, Yuping and Zhang, Zhensong and Wang, Yaxin and Ma,
   Ding and Huang, Jianbin},
	Book-Group-Author = {{IEEE}},
	Title = {{A Novel Fast and Memory Efficient Parallel MLCS Algorithm for Long and
   Large-Scale Sequences Alignments}},
	Booktitle = {{2016 32ND IEEE INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE)}},
	Series = {{IEEE International Conference on Data Engineering}},
	Year = {2016},
	Pages = {{1170-1181}},
	Note = {{32nd IEEE International Conference on Data Engineering (ICDE), Helsinki,
   FINLAND, MAY 16-20, 2016}},
	Organization = {{IEEE; IEEE Comp Soc; Aalto Univ, Sch Sci}},
	Abstract = {{Information usually can be abstracted as a character sequence over a
   finite alphabet. With the advent of the era of big data, the increasing
   length and size of the sequences from various application fields (e.g.,
   biological sequences) result in the classical NP-hard problem, searching
   for the Multiple Longest Common Subsequences of multiple sequences
   (i.e., MLCS problem with many applications in the areas of
   bioinformatics, computational genomics, pattern recognition, etc.),
   becoming a research hotspot and facing severe challenges. In this paper,
   we firstly reveal that the leading dominant-point-based MLCS algorithms
   are very hard to apply to long and large-scale sequences alignments. To
   overcome their defects, based on the proposed problem-solving model and
   parallel topological sorting strategies, we present a novel efficient
   parallel MLCS algorithm. The comprehensive experiments on the benchmark
   datasets of both random and biological sequences demonstrate that both
   the time and space complexities of the proposed algorithm are only
   linearly related to the dominants from aligned sequences, and that the
   proposed algorithm greatly outperforms the existing state-of-the-art
   dominant-point-based MLCS algorithms, and hence it is very suitable for
   long and large-scale sequences alignments.}},
	Publisher = {{IEEE}},
	Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
	Type = {{Proceedings Paper}},
	Language = {{English}},
	Affiliation = {{Li, YN (Reprint Author), Xidian Univ, Sch Software, Xian, Shaanxi, Peoples R China.
   Li, Yanni, Xidian Univ, Sch Software, Xian, Shaanxi, Peoples R China.
   Wang, Yuping, Xidian Univ, Sch Comp Sci \& Technol, Xian, Shaanxi, Peoples R China.
   Zhang, Zhensong, Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
   Wang, Yaxin, Univ Calif Los Angeles, Henry Samueli Sch Engn \& Appl Sci, Los Angeles, CA USA.
   Ma, Ding, Univ Southern Calif, Viterbi Sch Engn, Dept Comp Sci, Los Angeles, CA 90089 USA.
   Huang, Jianbin, Xidian Univ, Sch Software, Xian, Shaanxi, Peoples R China.}},
	ISSN = {{1084-4627}},
	ISBN = {{978-1-5090-2020-1}},
	Keywords = {{Multiple Longest Common Subsequences (MLCS); Irredundant Common
   Subsequence Graph (ICSG); Parallel Collection Chain (PCC); ICSG-PCC
   Model; Parallel Algorithm}},
	Keywords-Plus = {{COMMON SUBSEQUENCES}},
	Research-Areas = {{Computer Science; Engineering}},
	Web-of-Science-Categories = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
	Author-Email = {{yannili@mail.xidian.edu.cn
   ywang@xidian.edu.cn
   zszhang@cse.cuhk.edu.hk
   wangyaxinus@gmail.com
   dingma@usc.edu
   jbhuang@xidian.edu.cn}},
	Number-of-Cited-References = {{19}},
	Times-Cited = {{0}}
}

@inproceedings{Li2016_SIGKDD,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Li, Yanni and Li, Hui and Duan, Tihua and Wang, Sheng and Wang, Zhi and Cheng, Yang},
	title = {A Real Linear and Parallel Multiple Longest Common Subsequences (MLCS) Algorithm},
	booktitle = {Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	series = {KDD '16},
	year = {2016},
	isbn = {978-1-4503-4232-2},
	location = {San Francisco, California, USA},
	pages = {1725--1734},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/2939672.2939842},
	doi = {10.1145/2939672.2939842},
	acmid = {2939842},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {multiple longest common subsequences (mlcs), non-redu-ndant common subsequence graph (ncsg), subsection calculation and serialization, topological sorting}
}

@article{Lu2017,
	timestamp = {四 4月 20 11:16:55 2017},
	title = {EXPANDING SPEED OF THE HABITAT FOR A SPECIES IN AN ADVECTIVE ENVIRONMENT.},
	author = {Lu, Junfan and Gu, Hong and Lou, Bendong},
	journal = {Discrete \& Continuous Dynamical Systems-Series B},
	volume = {22},
	number = {2},
	year = {2017}
}

@article{Maier1978,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Maier, David},
	title = {The Complexity of Some Problems on Subsequences and Supersequences},
	journal = {J. ACM},
	issue_date = {April 1978},
	volume = {25},
	number = {2},
	month = apr,
	year = {1978},
	issn = {0004-5411},
	pages = {322--336},
	numpages = {15},
	url = {http://doi.acm.org/10.1145/322063.322075},
	doi = {10.1145/322063.322075},
	acmid = {322075},
	publisher = {ACM},
	address = {New York, NY, USA}
}

@article{Masek1980,
	timestamp = {四 4月 20 11:16:27 2017},
	title = "A faster algorithm computing string edit distances ",
	journal = "Journal of Computer and System Sciences ",
	volume = "20",
	number = "1",
	pages = "18 - 31",
	year = "1980",
	note = "",
	issn = "0022-0000",
	doi = "http://dx.doi.org/10.1016/0022-0000(80)90002-1",
	url = "http://www.sciencedirect.com/science/article/pii/0022000080900021",
	author = "William J. Masek and Michael S. Paterson",
	abstract = "The edit distance between two character strings can be defined as the minimum cost of a sequence of editing operations which transforms one string into the other. The operations we admit are deleting, inserting and replacing one symbol at a time, with possibly different costs for each of these operations. The problem of finding the longest common subsequence of two strings is a special case of the problem of computing edit distances. We describe an algorithm for computing the edit distance between two strings of length n and m, n ⪖ m, which requires O(n · max(1, mlog n)) steps whenever the costs of edit operations are integral multiples of a single positive real number and the alphabet for the strings is finite. These conditions are necessary for the algorithm to achieve the time bound. "
}

@article{Mittal2017,
	timestamp = {四 4月 20 11:16:55 2017},
	Author = {Mittal, Sunil and Kaur, Hardeep and Gautam, Nandini and Mantha, Anil K.},
	Title = {{Biosensors for breast cancer diagnosis: A review of bioreceptors,
   biotransducers and signal amplification strategies}},
	Journal = {{BIOSENSORS \& BIOELECTRONICS}},
	Year = {2017},
	Volume = {{88}},
	Number = {{SI}},
	Pages = {{217-231}},
	Month = {{FEB 15}},
	Note = {{26th Anniversary World Congress on Biosensors (Biosensors), Gothenburg,
   SWEDEN, MAY 24-28, 2016}},
	Organization = {{Ercon Inc}},
	Abstract = {{Breast cancer is highly prevalent in females and accounts for second
   highest number of deaths, worldwide. Cumbersome, expensive and time
   consuming detection techniques presently available for detection of
   breast cancer potentiates the need for development of novel, specific
   and ultrasensitive devices. Biosensors are the promising and selective
   detection devices which hold immense potential as point of care (POC)
   tools. Present review comprehensively scrutinizes various breast cancer
   biosensors developed so far and their technical evaluation with respect
   to efficiency and potency of selected bioreceptors and biotransducers.
   Use of glycoproteins, DNA biomarkers, micro-RNA, circulatory tumor cells
   (CTC) and some potential biomarkers are introduced briefly. The review
   also discusses various strategies used in signal amplification such as
   nanomaterials, redox mediators, p19 protein, duplex specific nucleases
   (DSN) and redox cycling. (C) 2016 Elsevier B.V. All rights reserved.}},
	Publisher = {{ELSEVIER ADVANCED TECHNOLOGY}},
	Address = {{OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON,
   OXFORD OX5 1GB, OXON, ENGLAND}},
	Type = {{Article; Proceedings Paper}},
	Language = {{English}},
	Affiliation = {{Kaur, H (Reprint Author), Cent Univ Punjab, Ctr Environm Sci \& Technol, Bathinda 151001, India.
   Mittal, Sunil; Kaur, Hardeep; Gautam, Nandini, Cent Univ Punjab, Ctr Environm Sci \& Technol, Bathinda 151001, India.
   Mantha, Anil K., Cent Univ Punjab, Ctr Anim Sci, Bathinda 151001, India.}},
	DOI = {{10.1016/j.bios.2016.08.028}},
	ISSN = {{0956-5663}},
	EISSN = {{1873-4235}},
	Keywords = {{Breast cancer; Biomarkers; Nanomaterials; Redox mediators; Redox cycling}},
	Keywords-Plus = {{SURFACE-PLASMON RESONANCE; CIRCULATING TUMOR-CELLS; LABEL-FREE
   DETECTION; ULTRASENSITIVE ELECTROCHEMICAL DETECTION; QUARTZ-CRYSTAL
   MICROBALANCE; HIGHLY SENSITIVE DETECTION; GROWTH-FACTOR RECEPTOR;
   SELF-ASSEMBLED MONOLAYERS; CARBOHYDRATE ANTIGEN 15-3; DUPLEX-SPECIFIC
   NUCLEASE}},
	Research-Areas = {{Biophysics; Biotechnology \& Applied Microbiology; Chemistry;
   Electrochemistry; Science \& Technology - Other Topics}},
	Web-of-Science-Categories = {{Biophysics; Biotechnology \& Applied Microbiology; Chemistry,
   Analytical; Electrochemistry; Nanoscience \& Nanotechnology}},
	Author-Email = {{sunil.cevs@gmail.com
   hardeep\_kaur007@rediffmail.com
   ngautam86@gmail.com
   anilmantha@gmail.com}},
	Number-of-Cited-References = {{184}},
	Times-Cited = {{0}}
}

@TECHREPORT{Rick1994,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Claus Rick and Claus Rick and Claus Rick},
	title = {New Algorithms for the Longest Common Subsequence Problem},
	institution = {},
	year = {1994}
}

@article{Sankoff1972,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {Sankoff, David},
	title = {Matching Sequences under Deletion/Insertion Constraints},
	volume = {69},
	number = {1},
	pages = {4-6},
	year = {1972},
	abstract = {Given two finite sequences, we wish to find the longest common subsequences satisfying certain deletion/insertion constraints. Consider two successive terms in the desired subsequence. The distance between their positions must be the same in the two original sequences for all but a limited number of such pairs of successive terms. Needleman and Wunsch gave an algorithm for finding longest common subsequences without constraints. This is improved from the viewpoint of computational economy. An economical algorithm is then elaborated for finding subsequences satisfying deletion/insertion constraints. This result is useful in the study of genetic homology based on nucleotide or amino-acid sequences.},
	URL = {http://www.pnas.org/content/69/1/4.abstract},
	eprint = {http://www.pnas.org/content/69/1/4.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@article{Smith1981,
	timestamp = {四 4月 20 11:16:27 2017},
	title = "Identification of common molecular subsequences",
	journal = "Journal of Molecular Biology",
	volume = "147",
	number = "1",
	pages = "195 - 197",
	year = "1981",
	note = "",
	issn = "0022-2836",
	doi = "http://dx.doi.org/10.1016/0022-2836(81)90087-5",
	url = "http://www.sciencedirect.com/science/article/pii/0022283681900875",
	author = "T.F. Smith and M.S. Waterman",
	abstract = ""
}

@article{Wang2011,
	timestamp = {四 4月 20 11:16:27 2017},
	Author = {Wang, Qingguo and Korkin, Dmitry and Shang, Yi},
	Title = {{A Fast Multiple Longest Common Subsequence (MLCS) Algorithm}},
	Journal = {{IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING}},
	Year = {2011},
	Volume = {{23}},
	Number = {{3}},
	Pages = {{321-334}},
	Month = {{MAR}},
	Abstract = {{Finding the longest common subsequence (LCS) of multiple strings is an
   NP-hard problem, with many applications in the areas of bioinformatics
   and computational genomics. Although significant efforts have been made
   to address the problem and its special cases, the increasing complexity
   and size of biological data require more efficient methods applicable to
   an arbitrary number of strings. In this paper, we present a new
   algorithm for the general case of multiple LCS (or MLCS) problem, i.e.,
   finding an LCS of any number of strings, and its parallel realization.
   The algorithm is based on the dominant point approach and employs a fast
   divide-and-conquer technique to compute the dominant points. When
   applied to a case of three strings, our algorithm demonstrates the same
   performance as the fastest existing MLCS algorithm designed for that
   specific case. When applied to more than three strings, our algorithm is
   significantly faster than the best existing sequential methods, reaching
   up to 2-3 orders of magnitude faster speed on large-size problems.
   Finally, we present an efficient parallel implementation of the
   algorithm. Evaluating the parallel algorithm on a benchmark set of both
   random and biological sequences reveals a near-linear speedup with
   respect to the sequential algorithm.}},
	Publisher = {{IEEE COMPUTER SOC}},
	Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
	Type = {{Article}},
	Language = {{English}},
	Affiliation = {{Wang, QG (Reprint Author), Univ Missouri, Dept Comp Sci, 207 Engn Bldg W, Columbia, MO 65211 USA.
   Wang, Qingguo; Korkin, Dmitry; Shang, Yi, Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
   Korkin, Dmitry, Univ Missouri, Inst Informat, Columbia, MO 65211 USA.}},
	DOI = {{10.1109/TKDE.2010.123}},
	ISSN = {{1041-4347}},
	EISSN = {{1558-2191}},
	Keywords = {{Longest common subsequence (LCS); multiple longest common subsequence
   (MLCS); dynamic programming; dominant point method; divide and conquer;
   parallel processing; multithreading}},
	Keywords-Plus = {{EFFICIENT PARALLEL ALGORITHMS; SEQUENCE MOTIFS; STRINGS; MAXIMA; LENGTH;
   PFAM; SET}},
	Research-Areas = {{Computer Science; Engineering}},
	Web-of-Science-Categories = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical \& Electronic}},
	Author-Email = {{qwp4b@mail.missouri.edu
   korkin@korkinlab.org
   shangy@missouri.edu}},
	ORCID-Numbers = {{Wang, Qingguo/0000-0002-5125-3724}},
	Funding-Acknowledgement = {{Shumaker Endowment in Bioinformatics; NIH {[}5R21GM078601-02]; US
   National Science Foundation (NSF) {[}DBI-0845196]}},
	Funding-Text = {{This research was supported in part by the Shumaker Endowment in
   Bioinformatics and NIH Grant 5R21GM078601-02. D. Korkin acknowledges
   funding from the US National Science Foundation (NSF) grant DBI-0845196.
   The authors are also grateful to the authors of FAST-LCS for sharing
   with them its code.}},
	Number-of-Cited-References = {{50}},
	Times-Cited = {{9}}
}

@article{Xue2015,
	timestamp = {四 4月 20 11:16:55 2017},
	Author = {Xue, Xingsi and Wang, Yuping},
	Title = {{Optimizing ontology alignments through a Memetic Algorithm using both
   MatchFmeasure and Unanimous Improvement Ratio}},
	Journal = {{ARTIFICIAL INTELLIGENCE}},
	Year = {2015},
	Volume = {{223}},
	Pages = {{65-81}},
	Month = {{JUN}},
	Abstract = {{There are three main drawbacks of current evolutionary approaches for
   determining the weights of ontology matching system. The first drawback
   is that it is difficult to simultaneously deal with several pairs of
   ontologies, i.e. finding a universal weight configuration that can be
   used for different ontology pairs without adjustment. The second one is
   that a reference alignment between two ontologies to be aligned should
   be given in advance which could be very expensive to obtain especially
   when the scale of ontologies is considerably large. The last one arises
   from f-measure, a generally used evaluation metric of the alignment's
   quality, which may cause the bias improvement of the solution. To
   overcome these three defects, in this paper, we propose to use both
   MatchFmeasure, a rough evaluation metric on no reference alignment to
   approximate f-measure, and Unanimous Improvement Ratio (UIR), a measure
   that complements MatchFmeasure, in the process of optimizing the
   ontology alignments by Memetic Algorithm (MA). The experimental results
   have shown that the MA using both MatchFmeasure and UIR is effective to
   simultaneously align multiple pairs of ontologies and avoid the bias
   improvement caused by MatchFeasure. Moreover, the comparison with
   state-of-the-art ontology matching systems further indicates the
   effectiveness of the proposed method. (C) 2015 Elsevier B.V. All rights
   reserved.}},
	Publisher = {{ELSEVIER SCIENCE BV}},
	Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
	Type = {{Article}},
	Language = {{English}},
	Affiliation = {{Wang, YP (Reprint Author), Xidian Univ, Sch Comp Sci \& Technol, Xian, Shaanxi, Peoples R China.
   Xue, Xingsi; Wang, Yuping, Xidian Univ, Sch Comp Sci \& Technol, Xian, Shaanxi, Peoples R China.
   Xue, Xingsi, Fujian Univ Technol, Sch Informat Sci \& Engn, Fuzhou, Fujian, Peoples R China.}},
	DOI = {{10.1016/j.artint.2015.03.001}},
	ISSN = {{0004-3702}},
	EISSN = {{1872-7921}},
	Keywords = {{Ontology alignment; Memetic Algorithm; MatchFmeasure; Unanimous
   Improvement Ratio}},
	Research-Areas = {{Computer Science}},
	Web-of-Science-Categories = {{Computer Science, Artificial Intelligence}},
	Author-Email = {{ywang@xidian.edu.cn}},
	Funding-Acknowledgement = {{National Natural Science Foundation of China {[}61272119, 61472297]}},
	Funding-Text = {{This work was supported by the National Natural Science Foundation of
   China (No. 61272119 and No. 61472297).}},
	Number-of-Cited-References = {{29}},
	Times-Cited = {{3}}
}

@article{Xue2016,
	timestamp = {四 4月 20 11:16:55 2017},
	Author = {Xue, Xingsi and Wang, Yuping},
	Title = {{Using Memetic Algorithm for Instance Coreference Resolution}},
	Journal = {{IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING}},
	Year = {2016},
	Volume = {{28}},
	Number = {{2}},
	Pages = {{580-591}},
	Month = {{FEB 1}},
	Note = {{IEEE 30th International Conference on Data Engineering (ICDE), Chicago,
   IL, MAR 31-APR 04, 2014}},
	Organization = {{IEEE; Microsoft; Qatar Comp Res Inst; HERE Nokia; Purdue Univ, Cyber
   Ctr; NW Univ, McCormick Sch Engn; Google}},
	Abstract = {{Instance coreference resolution is an essential problem in studying
   semantic web, and it is also critical for the implementation of web of
   data and future integration and application of semantic data. In this
   paper, we propose to use Memetic Algorithm (MA) to solve this instance
   coreference problem in a sequential stage, i.e., the instance-level
   matching is carried out with the result of schema-level matching. We
   first give the optimization model for schema-level matching and
   instance-level matching. Then, we, respectively, present profile
   similarity measures and the rough evaluation metrics with the assumption
   that the golden alignment for both schema-level matching and
   instance-level matching is one-to-one. Furthermore, we give the details
   of the MA. Finally, the experiments of comparing our approach with the
   state-of-the-art systems on OAEI benchmarks and real-world datasets are
   conducted and the results demonstrate that our approach is effective.}},
	Publisher = {{IEEE COMPUTER SOC}},
	Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
	Type = {{Article; Proceedings Paper}},
	Language = {{English}},
	Affiliation = {{Xue, XS; Wang, YP (Reprint Author), Xidian Univ, Sch Comp Sci \& Technol, Xian, Shaanxi, Peoples R China.
   Xue, XS (Reprint Author), Fujian Univ Technol, Sch Informat Sci \& Engn, Fuzhou, Fujian, Peoples R China.
   Xue, Xingsi; Wang, Yuping, Xidian Univ, Sch Comp Sci \& Technol, Xian, Shaanxi, Peoples R China.
   Xue, Xingsi, Fujian Univ Technol, Sch Informat Sci \& Engn, Fuzhou, Fujian, Peoples R China.}},
	DOI = {{10.1109/TKDE.2015.2475755}},
	ISSN = {{1041-4347}},
	EISSN = {{1558-2191}},
	Keywords = {{Instance coreference resolution; memetic algorithm; profile similarity
   measure}},
	Keywords-Plus = {{ONTOLOGY ALIGNMENT}},
	Research-Areas = {{Computer Science; Engineering}},
	Web-of-Science-Categories = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical \& Electronic}},
	Author-Email = {{jack8375@gmail.com
   ywang@xidian.edu.cn}},
	Funding-Acknowledgement = {{National Natural Science Foundation of China {[}61272119, 61472297,
   61503082]; Fundamental Research Funds for the Central Universities
   {[}BDZ021430]}},
	Funding-Text = {{This work was supported by the National Natural Science Foundation of
   China (Nos. 61272119, 61472297 and 61503082) and the Fundamental
   Research Funds for the Central Universities (Nos. BDZ021430).}},
	Number-of-Cited-References = {{44}},
	Times-Cited = {{0}}
}

@inproceedings{Yang2010,
	timestamp = {四 4月 20 11:16:27 2017},
	title = {An efficient parallel algorithm for longest common subsequence problem on GPUs},
	author = {Yang, Jiaoyun and Xu, Yun and Shang, Yi},
	booktitle = {Proceedings of the world congress on engineering, WCE},
	volume = {1},
	year = {2010}
}

@ARTICLE{Yang2013,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {J. Yang and Y. Xu and G. Sun and Y. Shang},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	title = {A New Progressive Algorithm for a Multiple Longest Common Subsequences Problem and Its Efficient Parallelization},
	year = {2013},
	volume = {24},
	number = {5},
	pages = {862-870},
	abstract = {The multiple longest common subsequence (MLCS) problem, which is related to the measurement of sequence similarity, is one of the fundamental problems in many fields. As an NP-hard problem, finding a good approximate solution within a reasonable time is important for solving large-size problems in practice. In this paper, we present a new progressive algorithm, Pro-MLCS, based on the dominant point approach. Pro-MLCS can find an approximate solution quickly and then progressively generate better solutions until obtaining the optimal one. Pro-MLCS employs three new techniques: 1) a new heuristic function for prioritizing candidate points; 2) a novel $(d)$-index-tree data structure for efficient computation of dominant points; and 3) a new pruning method using an upper bound function and approximate solutions. Experimental results show that Pro-MLCS can obtain the first approximate solution almost instantly and needs only a very small fraction, e.g., 3 percent, of the entire running time to get the optimal solution. Compared to existing state-of-the-art algorithms, Pro-MLCS can find better solutions in much shorter time, one to two orders of magnitude faster. In addition, two parallel versions of Pro-MLCS are developed: DPro-MLCS for distributed memory architecture and DSDPro-MLCS for hierarchical distributed shared memory architecture. Both parallel algorithms can efficiently utilize parallel computing resources and achieve nearly linear speedups. They also have a desirable progressiveness property&#x2014;finding better solutions in shorter time when given more hardware resources.},
	keywords = {Approximation algorithms;Complexity theory;DNA;Data structures;Heuristic algorithms;Memory architecture;Parallel algorithms;Multiple longest common subsequence problem (MLCS);SMP cluster;branch-and-bound search;distributed memory architecture;progressive algorithm;skyline problem},
	doi = {10.1109/TPDS.2012.202},
	ISSN = {1045-9219},
	month = {May}
}

@ARTICLE{Yang2014,
	timestamp = {四 4月 20 11:16:27 2017},
	author = {J. Yang and Y. Xu and Y. Shang and G. Chen},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	title = {A Space-Bounded Anytime Algorithm for the Multiple Longest Common Subsequence Problem},
	year = {2014},
	volume = {26},
	number = {11},
	pages = {2599-2609},
	abstract = {The multiple longest common subsequence (MLCS) problem, related to the identification of sequence similarity, is an important problem in many fields. As an NP-hard problem, its exact algorithms have difficulty in handling large-scale data and timeand space-efficient algorithms are required in real-world applications. To deal with time constraints, anytime algorithms have been proposed to generate good solutions with a reasonable time. However, there exists little work on space-efficient MLCS algorithms. In this paper, we formulate the MLCS problem into a graph search problem and present two space-efficient anytime MLCS algorithms, SA-MLCS and SLA-MLCS. SA-MLCS uses an iterative beam widening search strategy to reduce space usage during the iterative process of finding better solutions. Based on SA-MLCS, SLA-MLCS, a space-bounded algorithm, is developed to avoid space usage from exceeding available memory. SLA-MLCS uses a replacing strategy when SA-MLCS reaches a given space bound. Experimental results show SA-MLCS and SLA-MLCS use an order of magnitude less space and time than the state-of-the-art approximate algorithm MLCS-APP while finding better solutions. Compared to the state-of-the-art anytime algorithm Pro-MLCS, SA-MLCS and SLA-MLCS can solve an order of magnitude larger size instances. Furthermore, SLA-MLCS can find much better solutions than SA-MLCS on large size instances.},
	keywords = {approximation theory;computational complexity;data handling;graph theory;iterative methods;optimisation;search problems;MLCS-APP;NP-hard problem;SA-MLCS;SLA-MLCS;approximate algorithm;graph search problem;iterative beam widening search strategy;large-scale data handling;multiple longest common subsequence problem;replacing strategy;sequence similarity identification;space bounded anytime algorithm;space efficient anytime MLCS algorithm;space usage reduction;time constraint;time efficient algorithm;Algorithm design and analysis;Approximation algorithms;Dynamic programming;Educational institutions;Heuristic algorithms;Memory management;Search problems;Heuristic search;anytime algorithm;multiple longest common subsequence (MLCS);space bounded},
	doi = {10.1109/TKDE.2014.2304464},
	ISSN = {1041-4347},
	month = {Nov}
}

@Book{Zvelebil2007,
	year = {2007},
	publisher = {Garland Science},
	title = {Understanding bioinformatics},
	author = {M. Zvelebil and J. Baum},
	timestamp = {二 6月 27 16:02:01 2017}
}

@techreport{korkin2001,
	timestamp = {四 4月 20 11:16:27 2017},
	title = {A new dominant point-based parallel algorithm for multiple longest common subsequence problem},
	author = {Korkin, Dmitry},
	year = {2001},
	institution = {Technical report, Department of Computer Science, University of New Brunswick, NB Canada}
}

